{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-20T20:47:45.161802Z",
     "start_time": "2025-04-20T20:47:44.949143Z"
    }
   },
   "source": [
    "# generate_synthetic_data.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import os\n",
    "\n",
    "fake = Faker()\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T21:24:21.122904Z",
     "start_time": "2025-04-20T21:24:21.118092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === CONFIGURATION ===\n",
    "TARGET_FINAL_SIZE_GB = 10\n",
    "BYTES_PER_GB = 1024 ** 3\n",
    "\n",
    "# Estimated row size per table (bytes)\n",
    "ESTIMATED_ROW_SIZES = {\n",
    "    'persons': 200,\n",
    "    'applications': 300,\n",
    "    'loans': 300,\n",
    "    'vwlob': 150,\n",
    "    'wof': 150,\n",
    "    'transactions': 200,\n",
    "    'transactions_p2p': 200,\n",
    "    'credit_info': 300,\n",
    "    'income': 300\n",
    "}\n",
    "\n",
    "# Base counts to preserve proportions\n",
    "BASE_ROW_COUNTS = {\n",
    "    'persons': 300_000,\n",
    "    'applications': 5_000_000,\n",
    "    'loans': 3_000_000,\n",
    "    'vwlob': 250_000_000,\n",
    "    'wof': 100_000,\n",
    "    'transactions': 100_000_000,\n",
    "    'transactions_p2p': 50_000_000,\n",
    "    'credit_info': 8_000_000,\n",
    "    'income': 3_000_000\n",
    "}\n",
    "\n",
    "# Estimate total size of base dataset\n",
    "estimated_total_bytes = sum(BASE_ROW_COUNTS[table] * ESTIMATED_ROW_SIZES[table] for table in BASE_ROW_COUNTS)\n",
    "scaling_factor = (TARGET_FINAL_SIZE_GB * BYTES_PER_GB) / estimated_total_bytes\n",
    "\n",
    "# Scale all tables proportionally\n",
    "TARGET_ROW_COUNTS = {\n",
    "    table: max(1, int(BASE_ROW_COUNTS[table] * scaling_factor))\n",
    "    for table in BASE_ROW_COUNTS\n",
    "}\n",
    "\n",
    "print(f\"Estimated row counts to meet size goal (~{TARGET_FINAL_SIZE_GB}GB):\")\n",
    "for table, count in TARGET_ROW_COUNTS.items():\n",
    "    print(f\"- {table}: {count:,} rows\")"
   ],
   "id": "b763926bc3be1539",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated row counts to meet size goal (~5GB):\n",
      "- persons: 21,980 rows\n",
      "- applications: 366,339 rows\n",
      "- loans: 219,803 rows\n",
      "- vwlob: 18,316,987 rows\n",
      "- wof: 7,326 rows\n",
      "- transactions: 7,326,795 rows\n",
      "- transactions_p2p: 3,663,397 rows\n",
      "- credit_info: 586,143 rows\n",
      "- income: 219,803 rows\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T21:18:44.020708Z",
     "start_time": "2025-04-20T21:12:22.506125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === OUTPUT FOLDER ===\n",
    "os.makedirs(\"./synthetic_data\", exist_ok=True)\n",
    "\n",
    "# === GENERATION FUNCTIONS ===\n",
    "def generate_persons(n):\n",
    "    return pd.DataFrame({\n",
    "        'personid': range(1, n + 1),\n",
    "        'first_name': [fake.first_name() for _ in range(n)],\n",
    "        'last_name': [fake.last_name() for _ in range(n)],\n",
    "        'address': [fake.address().replace(\"\\n\", \", \") for _ in range(n)],\n",
    "        'birth_date': [fake.date_of_birth(minimum_age=18, maximum_age=70) for _ in range(n)],\n",
    "        'gender_id': np.random.choice([1, 2], size=n),\n",
    "        'maritalstatus_id': np.random.choice([1, 2, 3], size=n),\n",
    "    })\n",
    "\n",
    "def generate_applications(n, person_ids):\n",
    "    return pd.DataFrame({\n",
    "        'appid': range(1, n + 1),\n",
    "        'personid': np.random.choice(person_ids, size=n),\n",
    "        'productid': np.random.randint(1, 20, size=n),\n",
    "        'amount': np.round(np.random.uniform(500, 10000, size=n), 2),\n",
    "        'status_id': np.random.choice([1, 2, 3, 4], size=n),\n",
    "        'register_date': [fake.date_between(start_date='-3y', end_date='today') for _ in range(n)],\n",
    "    })\n",
    "\n",
    "def generate_loans(n, applications):\n",
    "    selected_apps = applications.sample(n)\n",
    "    return pd.DataFrame({\n",
    "        'loanid': range(1, n + 1),\n",
    "        'appid': selected_apps['appid'].values,\n",
    "        'personid': selected_apps['personid'].values,\n",
    "        'loan_size': selected_apps['amount'].values,\n",
    "        'loan_period': np.random.randint(6, 60, size=n),\n",
    "        'loan_percent': np.round(np.random.uniform(5, 25, size=n), 2),\n",
    "        'loan_value_date': [fake.date_between(start_date='-2y', end_date='-6m') for _ in range(n)],\n",
    "        'loan_end_date': [fake.date_between(start_date='-6m', end_date='+1y') for _ in range(n)],\n",
    "    })\n",
    "\n",
    "def generate_credit_info(n, appids):\n",
    "    return pd.DataFrame({\n",
    "        'appid': np.random.choice(appids, size=n),\n",
    "        'score': np.random.randint(300, 850, size=n),\n",
    "        'riskgrade': np.random.choice(['A', 'B', 'C', 'D', 'E'], size=n),\n",
    "        'click1': np.random.randint(0, 5, size=n),\n",
    "        'click3': np.random.randint(0, 10, size=n),\n",
    "        'click6': np.random.randint(0, 20, size=n),\n",
    "        'click12': np.random.randint(0, 30, size=n),\n",
    "        'probabilitydefault': np.random.rand(n),\n",
    "        'total_loans_count': np.random.randint(0, 10, size=n),\n",
    "        'total_loans_sum': np.round(np.random.uniform(0, 10000, size=n), 2),\n",
    "        'live_overdue_days': np.random.randint(0, 90, size=n),\n",
    "        'date': [fake.date_between(start_date='-1y', end_date='today') for _ in range(n)],\n",
    "    })\n",
    "\n",
    "def generate_income(n, appids, person_ids):\n",
    "    return pd.DataFrame({\n",
    "        'appid': np.random.choice(appids, size=n),\n",
    "        'personid': np.random.choice(person_ids, size=n),\n",
    "        'gross_income': np.round(np.random.uniform(500, 8000, size=n), 2),\n",
    "        'net_income': np.round(np.random.uniform(400, 7000, size=n), 2),\n",
    "        'income_type': np.random.choice(['salary', 'freelance', 'business'], size=n),\n",
    "        'expenses': np.round(np.random.uniform(100, 4000, size=n), 2),\n",
    "        'job_id': np.random.randint(1, 20, size=n),\n",
    "        'date': [fake.date_between(start_date='-2y', end_date='today') for _ in range(n)],\n",
    "    })\n",
    "\n",
    "def generate_transactions(n, person_ids):\n",
    "    return pd.DataFrame({\n",
    "        'transactionid': range(1, n + 1),\n",
    "        'personid': np.random.choice(person_ids, size=n),\n",
    "        'transaction_code': np.random.randint(100, 200, size=n),\n",
    "        'amount': np.round(np.random.uniform(5, 5000, size=n), 2),\n",
    "        'currency': np.random.choice(['USD', 'EUR', 'GEL'], size=n),\n",
    "        'merchant_id': np.random.randint(1, 1000, size=n),\n",
    "        'date': [fake.date_between(start_date='-2y', end_date='today') for _ in range(n)],\n",
    "    })\n",
    "\n",
    "def generate_transactions_p2p(n, person_ids):\n",
    "    return pd.DataFrame({\n",
    "        'transactionid': range(1, n + 1),\n",
    "        'personid_from': np.random.choice(person_ids, size=n),\n",
    "        'personid_to': np.random.choice(person_ids, size=n),\n",
    "        'transaction_code': np.random.randint(200, 300, size=n),\n",
    "        'amount': np.round(np.random.uniform(1, 3000, size=n), 2),\n",
    "        'currency': np.random.choice(['USD', 'EUR', 'GEL'], size=n),\n",
    "        'date': [fake.date_between(start_date='-2y', end_date='today') for _ in range(n)],\n",
    "    })\n",
    "\n",
    "def generate_wof(n, person_ids, loan_ids):\n",
    "    return pd.DataFrame({\n",
    "        'personid': np.random.choice(person_ids, size=n),\n",
    "        'loanid': np.random.choice(loan_ids, size=n),\n",
    "        'date': [fake.date_between(start_date='-2y', end_date='today') for _ in range(n)]\n",
    "    })\n",
    "\n",
    "def generate_related_persons(n, person_ids):\n",
    "    return pd.DataFrame({\n",
    "        'personid': np.random.choice(person_ids, size=n),\n",
    "        'related_personid': np.random.choice(person_ids, size=n),\n",
    "        'relationship_id': np.random.randint(1, 6, size=n),\n",
    "        'date': [fake.date_between(start_date='-5y', end_date='today') for _ in range(n)],\n",
    "        'is_valid': np.random.choice([True, False], size=n)\n",
    "    })\n",
    "\n",
    "def generate_vwlob(n, loans):\n",
    "    sampled_loans = loans.sample(n // 30, replace=True)  # simulate ~30 records per loan\n",
    "    records = []\n",
    "\n",
    "    for _, loan in sampled_loans.iterrows():\n",
    "        start_date = pd.to_datetime(loan['loan_value_date'])\n",
    "        end_date = pd.to_datetime(loan['loan_end_date'])\n",
    "        duration = (end_date - start_date).days\n",
    "\n",
    "        if duration < 20:\n",
    "            continue  # skip unrealistically short loans\n",
    "\n",
    "        daily_dates = pd.date_range(start=start_date, periods=min(duration, 30))\n",
    "        overdue_days = []\n",
    "        count = 0\n",
    "        state = 'increasing'\n",
    "\n",
    "        for _ in daily_dates:\n",
    "            if state == 'increasing':\n",
    "                count += 1\n",
    "                overdue_days.append(count)\n",
    "                if np.random.rand() < 0.1:\n",
    "                    state = 'zero'\n",
    "            elif state == 'zero':\n",
    "                overdue_days.append(0)\n",
    "                if np.random.rand() < 0.2:\n",
    "                    count = 1\n",
    "                    state = 'increasing'\n",
    "\n",
    "        for dt, od in zip(daily_dates, overdue_days):\n",
    "            records.append({\n",
    "                'appid': loan['appid'],\n",
    "                'loanid': loan['loanid'],\n",
    "                'overdue_days': od,\n",
    "                'monthly_date': dt\n",
    "            })\n",
    "\n",
    "            if len(records) >= n:\n",
    "                break\n",
    "        if len(records) >= n:\n",
    "            break\n",
    "\n",
    "    return pd.DataFrame.from_records(records)\n",
    "\n",
    "def save_parquet(df, name):\n",
    "    size_gb = df.memory_usage(deep=True).sum() / (1024 ** 3)\n",
    "    print(f\"Estimated in-memory size of '{name}': {size_gb:.3f} GB\")\n",
    "    table = pa.Table.from_pandas(df)\n",
    "    pq.write_table(table, f'./synthetic_data/{name}.parquet', compression=None)\n",
    "    \n",
    "# === GENERATE & SAVE ===\n",
    "persons_df = generate_persons(TARGET_ROW_COUNTS['persons'])\n",
    "save_parquet(persons_df, 'persons')\n",
    "\n",
    "applications_df = generate_applications(TARGET_ROW_COUNTS['applications'], persons_df['personid'].tolist())\n",
    "save_parquet(applications_df, 'applications')\n",
    "\n",
    "loans_df = generate_loans(TARGET_ROW_COUNTS['loans'], applications_df)\n",
    "save_parquet(loans_df, 'loans')\n",
    "\n",
    "credit_info_df = generate_credit_info(TARGET_ROW_COUNTS['credit_info'], applications_df['appid'].tolist())\n",
    "save_parquet(credit_info_df, 'credit_info')\n",
    "\n",
    "income_df = generate_income(TARGET_ROW_COUNTS['income'], applications_df['appid'].tolist(), persons_df['personid'].tolist())\n",
    "save_parquet(income_df, 'income')\n",
    "\n",
    "transactions_df = generate_transactions(TARGET_ROW_COUNTS['transactions'], persons_df['personid'].tolist())\n",
    "save_parquet(transactions_df, 'transactions')\n",
    "\n",
    "transactions_p2p_df = generate_transactions_p2p(TARGET_ROW_COUNTS['transactions_p2p'], persons_df['personid'].tolist())\n",
    "save_parquet(transactions_p2p_df, 'transactions_p2p')\n",
    "\n",
    "wof_df = generate_wof(TARGET_ROW_COUNTS['wof'], persons_df['personid'].tolist(), loans_df['loanid'].tolist())\n",
    "save_parquet(wof_df, 'wof')\n",
    "\n",
    "related_df = generate_related_persons(int(TARGET_ROW_COUNTS['persons'] * 0.5), persons_df['personid'].tolist())\n",
    "save_parquet(related_df, 'related_persons')\n",
    "\n",
    "vwlob_df = generate_vwlob(TARGET_ROW_COUNTS['vwlob'], loans_df)\n",
    "save_parquet(vwlob_df, 'vwlob')\n",
    "\n",
    "# Save target row counts for reference\n",
    "with open('./synthetic_data/row_counts.txt', 'w') as f:\n",
    "    for table, count in TARGET_ROW_COUNTS.items():\n",
    "        f.write(f\"{table}: {count}\\n\")"
   ],
   "id": "c1fbf7017fdc90dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated in-memory size of 'persons': 0.008 GB\n",
      "Estimated in-memory size of 'applications': 0.035 GB\n",
      "Estimated in-memory size of 'loans': 0.035 GB\n",
      "Estimated in-memory size of 'credit_info': 0.112 GB\n",
      "Estimated in-memory size of 'income': 0.041 GB\n",
      "Estimated in-memory size of 'transactions': 1.227 GB\n",
      "Estimated in-memory size of 'transactions_p2p': 0.632 GB\n",
      "Estimated in-memory size of 'wof': 0.001 GB\n",
      "Estimated in-memory size of 'related_persons': 0.001 GB\n",
      "Estimated in-memory size of 'vwlob': 0.357 GB\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a91b6121785be8e0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
