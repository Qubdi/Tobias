{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-03T10:53:14.999454Z",
     "start_time": "2025-05-03T10:53:12.061379Z"
    }
   },
   "source": [
    "from datetime import datetime, timedelta\n",
    "from faker import Faker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T10:53:15.127014Z",
     "start_time": "2025-05-03T10:53:15.016809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fake = Faker()\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "TARGET_FINAL_SIZE_GB = 0.1\n",
    "BYTES_PER_GB = 1024 ** 3\n",
    "\n",
    "\n",
    "\n",
    "# === REALISTIC CONSTANTS ===\n",
    "\n",
    "# Income distribution parameters (log-normal)\n",
    "INCOME_PARAMS = {\n",
    "    'mean_log': 10.5,  # log of median income ~$36,000\n",
    "    'std_log': 0.7,    # creates realistic income spread\n",
    "    'min_income': 15000,\n",
    "    'max_income': 1000000\n",
    "}\n",
    "\n",
    "# Credit score distribution (beta-scaled)\n",
    "CREDIT_SCORE_PARAMS = {\n",
    "    'alpha': 2.5,\n",
    "    'beta': 1.5,\n",
    "    'min_score': 300,\n",
    "    'max_score': 850\n",
    "}\n",
    "\n",
    "# Age demographics (mixture of normals)\n",
    "AGE_DEMOGRAPHICS = {\n",
    "    'young_adults': {'mean': 28, 'std': 5, 'weight': 0.25},\n",
    "    'middle_age': {'mean': 42, 'std': 8, 'weight': 0.45},\n",
    "    'senior': {'mean': 62, 'std': 8, 'weight': 0.30}\n",
    "}\n",
    "\n",
    "# Realistic loan parameters by product type\n",
    "LOAN_PRODUCTS = {\n",
    "    'Personal Loan': {\n",
    "        'min_amount': 1000, 'max_amount': 50000,\n",
    "        'min_term': 12, 'max_term': 60,\n",
    "        'base_rate': 8.0, 'risk_premium': 15.0\n",
    "    },\n",
    "    'Auto Loan': {\n",
    "        'min_amount': 5000, 'max_amount': 80000,\n",
    "        'min_term': 24, 'max_term': 84,\n",
    "        'base_rate': 4.0, 'risk_premium': 10.0\n",
    "    },\n",
    "    'Mortgage': {\n",
    "        'min_amount': 50000, 'max_amount': 1000000,\n",
    "        'min_term': 120, 'max_term': 360,\n",
    "        'base_rate': 3.0, 'risk_premium': 4.0\n",
    "    },\n",
    "    'Student Loan': {\n",
    "        'min_amount': 5000, 'max_amount': 100000,\n",
    "        'min_term': 60, 'max_term': 240,\n",
    "        'base_rate': 4.5, 'risk_premium': 3.0\n",
    "    },\n",
    "    'Credit Card': {\n",
    "        'min_amount': 500, 'max_amount': 50000,\n",
    "        'min_term': 0, 'max_term': 0,  # Revolving credit\n",
    "        'base_rate': 15.0, 'risk_premium': 10.0\n",
    "    },\n",
    "    'Business Loan': {\n",
    "        'min_amount': 10000, 'max_amount': 500000,\n",
    "        'min_term': 12, 'max_term': 120,\n",
    "        'base_rate': 6.0, 'risk_premium': 12.0\n",
    "    }\n",
    "}\n",
    "\n",
    "# Employment sectors with realistic income distributions\n",
    "EMPLOYMENT_SECTORS = {\n",
    "    'Technology': {'income_multiplier': 1.4, 'stability': 0.85, 'growth_rate': 0.08},\n",
    "    'Finance': {'income_multiplier': 1.5, 'stability': 0.80, 'growth_rate': 0.06},\n",
    "    'Healthcare': {'income_multiplier': 1.3, 'stability': 0.90, 'growth_rate': 0.05},\n",
    "    'Education': {'income_multiplier': 0.9, 'stability': 0.95, 'growth_rate': 0.03},\n",
    "    'Retail': {'income_multiplier': 0.7, 'stability': 0.60, 'growth_rate': 0.02},\n",
    "    'Manufacturing': {'income_multiplier': 1.0, 'stability': 0.75, 'growth_rate': 0.03},\n",
    "    'Government': {'income_multiplier': 1.1, 'stability': 0.95, 'growth_rate': 0.04},\n",
    "    'Construction': {'income_multiplier': 1.1, 'stability': 0.65, 'growth_rate': 0.04},\n",
    "    'Services': {'income_multiplier': 0.8, 'stability': 0.70, 'growth_rate': 0.03}\n",
    "}\n",
    "\n",
    "# Transaction patterns by category\n",
    "TRANSACTION_PATTERNS = {\n",
    "    'Essential': {\n",
    "        'Groceries': {'freq_per_month': 8, 'amount_range': (50, 300), 'variance': 0.2},\n",
    "        'Utilities': {'freq_per_month': 3, 'amount_range': (100, 400), 'variance': 0.1},\n",
    "        'Housing': {'freq_per_month': 1, 'amount_range': (800, 3000), 'variance': 0.05},\n",
    "        'Transportation': {'freq_per_month': 10, 'amount_range': (20, 200), 'variance': 0.3},\n",
    "        'Healthcare': {'freq_per_month': 0.5, 'amount_range': (50, 500), 'variance': 0.5}\n",
    "    },\n",
    "    'Discretionary': {\n",
    "        'Dining': {'freq_per_month': 6, 'amount_range': (20, 150), 'variance': 0.4},\n",
    "        'Entertainment': {'freq_per_month': 4, 'amount_range': (20, 200), 'variance': 0.5},\n",
    "        'Shopping': {'freq_per_month': 3, 'amount_range': (50, 500), 'variance': 0.6},\n",
    "        'Travel': {'freq_per_month': 0.2, 'amount_range': (200, 2000), 'variance': 0.7}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Risk factors and their weights\n",
    "RISK_FACTORS = {\n",
    "    'credit_score': {'weight': 0.35, 'threshold': 650},\n",
    "    'dti_ratio': {'weight': 0.25, 'threshold': 0.43},\n",
    "    'payment_history': {'weight': 0.20, 'threshold': 0.95},\n",
    "    'employment_stability': {'weight': 0.10, 'threshold': 0.7},\n",
    "    'income_verification': {'weight': 0.10, 'threshold': 0.9}\n",
    "}\n",
    "\n",
    "# === MORE REALISTIC ROW COUNTS ===\n",
    "BASE_ROW_COUNTS = {\n",
    "    'persons': 100_000,              # 100K unique customers\n",
    "    'person_employment': 150_000,     # 1.5 jobs per person average\n",
    "    'applications': 250_000,          # 2.5 applications per person average\n",
    "    'application_financial': 250_000, # One per application\n",
    "    'credit_scoring': 250_000,        # One per application\n",
    "    'loans': 150_000,                 # 60% approval rate\n",
    "    'loan_payments': 2_000_000,       # ~25 payments per loan\n",
    "    'guarantors': 8_000,              # 5.3% of loans have guarantors\n",
    "    'collateral': 15_000,             # 10% of loans have collateral\n",
    "    'transactions': 10_000_000,       # 100 transactions per person per month\n",
    "    'transactions_p2p': 2_000_000,    # 20 P2P per person per month\n",
    "    'wof': 2_000,                     # 1.3% default rate\n",
    "    'related_persons': 10_000         # 10% have related persons\n",
    "}\n",
    "\n",
    "# === TABLE SIZE ESTIMATION ===\n",
    "ESTIMATED_ROW_SIZES = {\n",
    "    'persons': 400,\n",
    "    'person_employment': 350,\n",
    "    'applications': 400,\n",
    "    'application_financial': 600,\n",
    "    'credit_scoring': 800,\n",
    "    'loans': 450,\n",
    "    'loan_payments': 350,\n",
    "    'guarantors': 300,\n",
    "    'collateral': 450,\n",
    "    'transactions': 300,\n",
    "    'transactions_p2p': 300,\n",
    "    'wof': 250,\n",
    "    'related_persons': 200\n",
    "}\n",
    "\n",
    "TARGET_FINAL_SIZE_GB_WITHOUT_WLOB = TARGET_FINAL_SIZE_GB / 1.8\n",
    "\n",
    "# Calculate scaling factor\n",
    "estimated_total_bytes = sum(BASE_ROW_COUNTS[table] * ESTIMATED_ROW_SIZES[table]\n",
    "                          for table in BASE_ROW_COUNTS)\n",
    "scaling_factor = (TARGET_FINAL_SIZE_GB_WITHOUT_WLOB * BYTES_PER_GB) / estimated_total_bytes\n",
    "\n",
    "# Scale all tables proportionally\n",
    "TARGET_ROW_COUNTS = {\n",
    "    table: max(1, int(BASE_ROW_COUNTS[table] * scaling_factor))\n",
    "    for table in BASE_ROW_COUNTS\n",
    "}\n",
    "\n",
    "TARGET_ROW_COUNTS"
   ],
   "id": "b763926bc3be1539",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'persons': 1212,\n",
       " 'person_employment': 1818,\n",
       " 'applications': 3030,\n",
       " 'application_financial': 3030,\n",
       " 'credit_scoring': 3030,\n",
       " 'loans': 1818,\n",
       " 'loan_payments': 24240,\n",
       " 'guarantors': 96,\n",
       " 'collateral': 181,\n",
       " 'transactions': 121203,\n",
       " 'transactions_p2p': 24240,\n",
       " 'wof': 24,\n",
       " 'related_persons': 121}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T10:53:16.095441Z",
     "start_time": "2025-05-03T10:53:15.813113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === HELPER FUNCTIONS ===\n",
    "\n",
    "def generate_correlated_values(n, correlation_matrix, means, stds):\n",
    "    \"\"\"Generate correlated random variables\"\"\"\n",
    "    # Generate uncorrelated standard normal variables\n",
    "    uncorrelated = np.random.randn(n, len(means))\n",
    "\n",
    "    # Apply Cholesky decomposition to create correlation\n",
    "    L = np.linalg.cholesky(correlation_matrix)\n",
    "    correlated = uncorrelated @ L.T\n",
    "\n",
    "    # Scale and shift to desired means and standard deviations\n",
    "    scaled = correlated * stds + means\n",
    "\n",
    "    return scaled\n",
    "\n",
    "def generate_realistic_ages(n):\n",
    "    \"\"\"Generate realistic age distribution - OPTIMIZED\"\"\"\n",
    "    # Vectorized approach\n",
    "    groups = list(AGE_DEMOGRAPHICS.keys())\n",
    "    probs = [demo['weight'] for demo in AGE_DEMOGRAPHICS.values()]\n",
    "\n",
    "    # Generate all group choices at once\n",
    "    chosen_groups = np.random.choice(groups, size=n, p=probs)\n",
    "\n",
    "    # Pre-compute means and stds for all groups\n",
    "    group_means = {group: AGE_DEMOGRAPHICS[group]['mean'] for group in groups}\n",
    "    group_stds = {group: AGE_DEMOGRAPHICS[group]['std'] for group in groups}\n",
    "\n",
    "    # Vectorized age generation\n",
    "    ages = np.zeros(n)\n",
    "    for group in groups:\n",
    "        mask = chosen_groups == group\n",
    "        count = np.sum(mask)\n",
    "        if count > 0:\n",
    "            ages[mask] = np.random.normal(group_means[group], group_stds[group], count)\n",
    "\n",
    "    # Clip ages in one operation\n",
    "    return np.clip(ages, 18, 85).astype(int)\n",
    "\n",
    "def generate_income_distribution(n):\n",
    "    \"\"\"Generate realistic income distribution - ALREADY OPTIMIZED\"\"\"\n",
    "    log_incomes = np.random.normal(INCOME_PARAMS['mean_log'],\n",
    "                                  INCOME_PARAMS['std_log'], n)\n",
    "    incomes = np.exp(log_incomes)\n",
    "    incomes = np.clip(incomes, INCOME_PARAMS['min_income'],\n",
    "                     INCOME_PARAMS['max_income'])\n",
    "    return incomes\n",
    "\n",
    "def generate_credit_scores(n, incomes, ages):\n",
    "    \"\"\"Generate credit scores correlated with income and age - ALREADY OPTIMIZED\"\"\"\n",
    "    # All operations are already vectorized using numpy\n",
    "    beta_scores = np.random.beta(CREDIT_SCORE_PARAMS['alpha'],\n",
    "                                CREDIT_SCORE_PARAMS['beta'], n)\n",
    "    base_scores = CREDIT_SCORE_PARAMS['min_score'] + beta_scores * (\n",
    "        CREDIT_SCORE_PARAMS['max_score'] - CREDIT_SCORE_PARAMS['min_score']\n",
    "    )\n",
    "\n",
    "    income_factor = np.log(incomes) / np.log(INCOME_PARAMS['max_income'])\n",
    "    income_adjustment = income_factor * 100\n",
    "\n",
    "    age_factor = np.clip((ages - 18) / 50, 0, 1)\n",
    "    age_adjustment = age_factor * 50\n",
    "\n",
    "    final_scores = base_scores + income_adjustment + age_adjustment\n",
    "    noise = np.random.normal(0, 30, n)\n",
    "    final_scores = np.clip(final_scores + noise,\n",
    "                          CREDIT_SCORE_PARAMS['min_score'],\n",
    "                          CREDIT_SCORE_PARAMS['max_score'])\n",
    "\n",
    "    return final_scores.astype(int)\n",
    "\n",
    "def generate_persons(n):\n",
    "    \"\"\"Generate ultra high-quality person data with realistic correlations - OPTIMIZED\"\"\"\n",
    "    # Generate correlated demographic features\n",
    "    ages = generate_realistic_ages(n)\n",
    "    incomes = generate_income_distribution(n)\n",
    "    credit_scores = generate_credit_scores(n, incomes, ages)\n",
    "\n",
    "    # Vectorized education levels\n",
    "    education_choices = ['High School', 'Some College', 'Bachelor', 'Master', 'PhD']\n",
    "\n",
    "    # Create income brackets\n",
    "    income_brackets = np.digitize(incomes, [30000, 60000, 100000, 200000])\n",
    "\n",
    "    # Pre-defined probabilities for each bracket\n",
    "    education_probs = {\n",
    "        0: [0.50, 0.30, 0.15, 0.04, 0.01],\n",
    "        1: [0.30, 0.30, 0.30, 0.08, 0.02],\n",
    "        2: [0.15, 0.20, 0.40, 0.20, 0.05],\n",
    "        3: [0.05, 0.10, 0.40, 0.35, 0.10],\n",
    "        4: [0.02, 0.08, 0.30, 0.40, 0.20]\n",
    "    }\n",
    "\n",
    "    # Vectorized education generation\n",
    "    education_levels = np.empty(n, dtype=object)\n",
    "    for bracket in range(5):\n",
    "        mask = income_brackets == bracket\n",
    "        count = np.sum(mask)\n",
    "        if count > 0:\n",
    "            education_levels[mask] = np.random.choice(\n",
    "                education_choices,\n",
    "                size=count,\n",
    "                p=education_probs[bracket]\n",
    "            )\n",
    "\n",
    "    # Vectorized gender generation\n",
    "    genders = np.random.choice(['M', 'F', 'O'], size=n, p=[0.49, 0.49, 0.02])\n",
    "\n",
    "    # Vectorized marital status\n",
    "    age_brackets = np.digitize(ages, [25, 35, 50])\n",
    "    marital_probs = {\n",
    "        0: [0.80, 0.15, 0.04, 0.01],\n",
    "        1: [0.40, 0.50, 0.08, 0.02],\n",
    "        2: [0.20, 0.60, 0.15, 0.05],\n",
    "        3: [0.15, 0.50, 0.20, 0.15]\n",
    "    }\n",
    "\n",
    "    marital_statuses = np.empty(n, dtype=object)\n",
    "    marital_choices = ['Single', 'Married', 'Divorced', 'Widowed']\n",
    "    for bracket in range(4):\n",
    "        mask = age_brackets == bracket\n",
    "        count = np.sum(mask)\n",
    "        if count > 0:\n",
    "            marital_statuses[mask] = np.random.choice(\n",
    "                marital_choices,\n",
    "                size=count,\n",
    "                p=marital_probs[bracket]\n",
    "            )\n",
    "\n",
    "    # Vectorized home ownership\n",
    "    ownership_prob = np.minimum(0.9, 0.1 + (ages - 18) / 100 + incomes / 500000)\n",
    "    owns_home = np.random.random(n) < ownership_prob\n",
    "\n",
    "    # Vectorized home status selection\n",
    "    home_ownerships = np.empty(n, dtype=object)\n",
    "    home_ownerships[~owns_home] = 'Rent'\n",
    "\n",
    "    # For those who own\n",
    "    high_income_owners = owns_home & (incomes > 100000)\n",
    "    low_income_owners = owns_home & (incomes <= 100000)\n",
    "\n",
    "    home_ownerships[high_income_owners] = np.random.choice(\n",
    "        ['Own', 'Mortgage'],\n",
    "        size=np.sum(high_income_owners),\n",
    "        p=[0.3, 0.7]\n",
    "    )\n",
    "    home_ownerships[low_income_owners] = np.random.choice(\n",
    "        ['Own', 'Mortgage'],\n",
    "        size=np.sum(low_income_owners),\n",
    "        p=[0.1, 0.9]\n",
    "    )\n",
    "\n",
    "    # Geographic distribution\n",
    "    states = ['CA', 'TX', 'FL', 'NY', 'PA', 'IL', 'OH', 'GA', 'NC', 'MI']\n",
    "    state_weights = [0.15, 0.12, 0.10, 0.10, 0.08, 0.08, 0.07, 0.07, 0.07, 0.06]\n",
    "    states_selected = np.random.choice(states, size=n, p=state_weights/np.sum(state_weights))\n",
    "\n",
    "    # Vectorized date generation\n",
    "    current_date = datetime.now()\n",
    "    dob_dates = [current_date - timedelta(days=int(age*365.25)) for age in ages]\n",
    "    customer_since_dates = [fake.date_between(start_date='-15y', end_date='today') for _ in range(n)]\n",
    "    created_dates = [fake.date_time_between(start_date='-5y', end_date='now') for _ in range(n)]\n",
    "    updated_dates = [fake.date_time_between(start_date='-1y', end_date='now') for _ in range(n)]\n",
    "\n",
    "    # Vectorized dependent calculation\n",
    "    married_mask = marital_statuses == 'Married'\n",
    "    dependents = np.where(married_mask,\n",
    "                         np.random.poisson(1.5, n),\n",
    "                         np.random.poisson(0.3, n))\n",
    "\n",
    "    # Create the dataframe\n",
    "    persons_df = pd.DataFrame({\n",
    "        'personid': range(1, n + 1),\n",
    "        'first_name': [fake.first_name() for _ in range(n)],\n",
    "        'last_name': [fake.last_name() for _ in range(n)],\n",
    "        'email': [f\"{fake.user_name()}@{fake.free_email_domain()}\" for _ in range(n)],\n",
    "        'phone': [fake.phone_number()[:15] for _ in range(n)],\n",
    "        'ssn': [fake.ssn() for _ in range(n)],\n",
    "        'date_of_birth': dob_dates,\n",
    "        'age': ages,\n",
    "        'gender': genders,\n",
    "        'marital_status': marital_statuses,\n",
    "        'education_level': education_levels,\n",
    "        'annual_income': incomes.round(2),\n",
    "        'credit_score': credit_scores,\n",
    "        'address_street': [fake.street_address() for _ in range(n)],\n",
    "        'address_city': [fake.city() for _ in range(n)],\n",
    "        'address_state': states_selected,\n",
    "        'address_zip': [fake.postcode()[:5] for _ in range(n)],\n",
    "        'home_ownership': home_ownerships,\n",
    "        'years_at_address': np.random.exponential(5, n).round(1).clip(0, 30),\n",
    "        'dependents': dependents,\n",
    "        'customer_since': customer_since_dates,\n",
    "        'customer_segment': pd.qcut(incomes + credit_scores * 10,\n",
    "                                   q=4,\n",
    "                                   labels=['Basic', 'Standard', 'Premium', 'Elite']),\n",
    "        'risk_category': pd.qcut(credit_scores,\n",
    "                                q=4,\n",
    "                                labels=['High Risk', 'Medium Risk', 'Low Risk', 'Very Low Risk']),\n",
    "        'is_active': np.random.choice([True, False], size=n, p=[0.92, 0.08]),\n",
    "        'preferred_contact': np.random.choice(['Email', 'Phone', 'Mail', 'SMS'],\n",
    "                                            size=n, p=[0.45, 0.25, 0.10, 0.20]),\n",
    "        'occupation_category': np.random.choice(['Professional', 'Technical', 'Service',\n",
    "                                               'Sales', 'Administrative', 'Labor', 'Other'],\n",
    "                                              size=n),\n",
    "        'created_at': created_dates,\n",
    "        'updated_at': updated_dates\n",
    "    })\n",
    "\n",
    "    return persons_df\n",
    "\n",
    "def generate_person_employment(n, persons_df):\n",
    "    \"\"\"Generate employment history with realistic career progressions - OPTIMIZED\"\"\"\n",
    "    # Pre-calculate employment counts for all persons\n",
    "    employment_counts = np.random.poisson(1.5, len(persons_df)).clip(0, 5)\n",
    "\n",
    "    # Calculate career start ages and work years for all persons at once\n",
    "    career_start_ages = persons_df['education_level'].map({\n",
    "        'High School': 18,\n",
    "        'Some College': 20,\n",
    "        'Bachelor': 22,\n",
    "        'Master': 24,\n",
    "        'PhD': 27\n",
    "    }).fillna(18)\n",
    "\n",
    "    work_years = np.maximum(0, persons_df['age'] - career_start_ages)\n",
    "\n",
    "    # Pre-allocate lists for batch processing\n",
    "    employment_records = []\n",
    "    current_time = datetime.now()\n",
    "\n",
    "    # Vectorized sector selection probabilities\n",
    "    education_level_probs = {\n",
    "        ('Master', 'PhD'): [0.25, 0.20, 0.15, 0.15, 0.05, 0.05, 0.10, 0.02, 0.03],\n",
    "        ('Bachelor',): [0.20, 0.15, 0.10, 0.05, 0.10, 0.15, 0.10, 0.05, 0.10],\n",
    "        ('High School', 'Some College'): [0.05, 0.05, 0.10, 0.05, 0.20, 0.20, 0.05, 0.15, 0.15]\n",
    "    }\n",
    "\n",
    "    # Process persons in batches for memory efficiency\n",
    "    for idx, person in persons_df.iterrows():\n",
    "        num_jobs = employment_counts[idx]\n",
    "        work_year = work_years[idx]\n",
    "\n",
    "        if work_year == 0 or num_jobs == 0:\n",
    "            continue\n",
    "\n",
    "        years_per_job = work_year / max(1, num_jobs)\n",
    "\n",
    "        # Determine sector probabilities\n",
    "        for edu_group, probs in education_level_probs.items():\n",
    "            if person['education_level'] in edu_group:\n",
    "                sector_probs = probs\n",
    "                break\n",
    "        else:\n",
    "            sector_probs = education_level_probs[('High School', 'Some College')]\n",
    "\n",
    "        # Generate all sectors at once for this person's jobs\n",
    "        sectors = np.random.choice(list(EMPLOYMENT_SECTORS.keys()),\n",
    "                                 size=min(num_jobs, n - len(employment_records)),\n",
    "                                 p=sector_probs)\n",
    "\n",
    "        # Vectorized position level determination\n",
    "        experiences = work_year - np.arange(num_jobs) * years_per_job\n",
    "        position_levels = np.where(experiences < 2, 'Junior',\n",
    "                          np.where(experiences < 5, '',\n",
    "                          np.where(experiences < 10, 'Senior',\n",
    "                          np.where(experiences < 15, 'Lead', 'Director'))))\n",
    "\n",
    "        # Generate employment records for this person\n",
    "        for job_idx in range(min(num_jobs, n - len(employment_records))):\n",
    "            sector = sectors[job_idx]\n",
    "            sector_info = EMPLOYMENT_SECTORS[sector]\n",
    "\n",
    "            # Calculate salary\n",
    "            if job_idx == 0:  # Current job\n",
    "                base_salary = person['annual_income']\n",
    "            else:\n",
    "                years_ago = job_idx * years_per_job\n",
    "                growth_factor = (1 + sector_info['growth_rate']) ** (-years_ago)\n",
    "                base_salary = person['annual_income'] * growth_factor\n",
    "\n",
    "            sector_salary = base_salary * sector_info['income_multiplier']\n",
    "\n",
    "            # Calculate dates\n",
    "            if job_idx == 0:\n",
    "                start_date = current_time - timedelta(days=int(years_per_job * 365))\n",
    "                end_date = None\n",
    "                is_current = True\n",
    "                employment_status = 'Full-time'\n",
    "            else:\n",
    "                end_date = current_time - timedelta(days=int((job_idx - 0.5) * years_per_job * 365))\n",
    "                start_date = end_date - timedelta(days=int(years_per_job * 365))\n",
    "                is_current = False\n",
    "                employment_status = np.random.choice(['Full-time', 'Part-time', 'Contract'],\n",
    "                                                   p=[0.8, 0.1, 0.1])\n",
    "\n",
    "            position_title = f\"{position_levels[job_idx]} {fake.job()}\".strip()\n",
    "\n",
    "            employment_records.append({\n",
    "                'employment_id': len(employment_records) + 1,\n",
    "                'personid': person['personid'],\n",
    "                'employer_name': fake.company(),\n",
    "                'employer_industry': sector,\n",
    "                'position_title': position_title,\n",
    "                'employment_status': employment_status,\n",
    "                'start_date': start_date,\n",
    "                'end_date': end_date,\n",
    "                'annual_salary': round(sector_salary, 2),\n",
    "                'monthly_salary': round(sector_salary / 12, 2),\n",
    "                'years_in_role': round(years_per_job, 1),\n",
    "                'total_experience': round(experiences[job_idx], 1),\n",
    "                'is_current': is_current,\n",
    "                'performance_rating': np.random.choice(['Exceeds', 'Meets', 'Below'],\n",
    "                                                     p=[0.2, 0.7, 0.1]),\n",
    "                'termination_reason': None if is_current else np.random.choice(\n",
    "                    ['Better Opportunity', 'Layoff', 'Resignation', 'Contract End'],\n",
    "                    p=[0.6, 0.1, 0.2, 0.1]\n",
    "                ),\n",
    "                'employer_size': np.random.choice(['Small', 'Medium', 'Large', 'Enterprise'],\n",
    "                                                p=[0.3, 0.3, 0.2, 0.2]),\n",
    "                'verification_status': np.random.choice(['Verified', 'Pending', 'Unverified'],\n",
    "                                                      p=[0.7, 0.2, 0.1]),\n",
    "                'created_at': fake.date_time_between(start_date='-3y', end_date='now'),\n",
    "                'updated_at': fake.date_time_between(start_date='-1y', end_date='now')\n",
    "            })\n",
    "\n",
    "            if len(employment_records) >= n:\n",
    "                break\n",
    "\n",
    "        if len(employment_records) >= n:\n",
    "            break\n",
    "\n",
    "    return pd.DataFrame(employment_records[:n])\n",
    "\n",
    "def generate_applications(n, persons_df, employment_df):\n",
    "    \"\"\"Generate historical loan applications with approved amounts - ALREADY OPTIMIZED\"\"\"\n",
    "    # The existing code is already highly vectorized\n",
    "    # Let's make just a few minor improvements\n",
    "\n",
    "    # Sample persons for applications\n",
    "    person_sample = persons_df.sample(n, replace=True).reset_index(drop=True)\n",
    "\n",
    "    # Get current employment information\n",
    "    current_employment = employment_df[employment_df['is_current'] == True].set_index('personid')\n",
    "\n",
    "    # Vectorized has employment check\n",
    "    has_employment = person_sample['personid'].isin(current_employment.index).values\n",
    "\n",
    "    # Vectorized product selection\n",
    "    high_income_mask = (person_sample['annual_income'] > 100000) & (person_sample['credit_score'] > 720)\n",
    "    young_mask = person_sample['age'] < 25\n",
    "    low_income_mask = person_sample['annual_income'] < 40000\n",
    "\n",
    "    # Product names and probabilities\n",
    "    product_names = list(LOAN_PRODUCTS.keys())\n",
    "\n",
    "    # Vectorized product type selection using numpy choice\n",
    "    probs_matrix = np.array([\n",
    "        [0.25, 0.25, 0.2, 0.1, 0.15, 0.05],  # default\n",
    "        [0.2, 0.2, 0.3, 0.05, 0.15, 0.1],     # high_income\n",
    "        [0.3, 0.2, 0.05, 0.35, 0.1, 0.0],     # young\n",
    "        [0.4, 0.1, 0.05, 0.1, 0.3, 0.05]      # low_income\n",
    "    ])\n",
    "\n",
    "    # Create condition array\n",
    "    conditions = np.zeros(n, dtype=int)\n",
    "    conditions[high_income_mask] = 1\n",
    "    conditions[young_mask] = 2\n",
    "    conditions[low_income_mask] = 3\n",
    "\n",
    "    # Generate all product types at once\n",
    "    product_types = np.array([\n",
    "        np.random.choice(product_names, p=probs_matrix[cond])\n",
    "        for cond in conditions\n",
    "    ])\n",
    "\n",
    "    # Vectorized calculations for all loan parameters\n",
    "    product_info_dict = {pt: LOAN_PRODUCTS[pt] for pt in product_names}\n",
    "\n",
    "    # Vectorized max amount calculation\n",
    "    max_amounts = np.zeros(n)\n",
    "    for pt in product_names:\n",
    "        mask = product_types == pt\n",
    "        if np.any(mask):\n",
    "            if pt == 'Mortgage':\n",
    "                max_amounts[mask] = np.minimum(\n",
    "                    product_info_dict[pt]['max_amount'],\n",
    "                    person_sample.loc[mask, 'annual_income'] * 5\n",
    "                )\n",
    "            elif pt == 'Auto Loan':\n",
    "                max_amounts[mask] = np.minimum(\n",
    "                    product_info_dict[pt]['max_amount'],\n",
    "                    person_sample.loc[mask, 'annual_income'] * 0.5\n",
    "                )\n",
    "            elif pt == 'Credit Card':\n",
    "                max_amounts[mask] = np.minimum(\n",
    "                    product_info_dict[pt]['max_amount'],\n",
    "                    person_sample.loc[mask, 'annual_income'] * 0.3\n",
    "                )\n",
    "            else:\n",
    "                max_amounts[mask] = np.minimum(\n",
    "                    product_info_dict[pt]['max_amount'],\n",
    "                    person_sample.loc[mask, 'annual_income'] * 1.5\n",
    "                )\n",
    "\n",
    "    # Vectorized min amounts and requested amounts\n",
    "    min_amounts = np.array([product_info_dict[pt]['min_amount'] for pt in product_types])\n",
    "    requested_amounts = np.random.uniform(min_amounts, max_amounts)\n",
    "\n",
    "    # Vectorized term months\n",
    "    term_months = np.array([\n",
    "        0 if pt == 'Credit Card' else\n",
    "        np.random.randint(product_info_dict[pt]['min_term'],\n",
    "                         product_info_dict[pt]['max_term'] + 1)\n",
    "        for pt in product_types\n",
    "    ])\n",
    "\n",
    "    # Vectorized interest rates\n",
    "    base_rates = np.array([product_info_dict[pt]['base_rate'] for pt in product_types])\n",
    "    risk_premiums = np.array([product_info_dict[pt]['risk_premium'] for pt in product_types])\n",
    "    credit_factors = (850 - person_sample['credit_score'].values) / 550\n",
    "    interest_rates = base_rates + risk_premiums * credit_factors\n",
    "\n",
    "    # Vectorized channel selection\n",
    "    young_small_loan = (person_sample['age'] < 35) & (requested_amounts < 50000)\n",
    "    large_loan = requested_amounts > 100000\n",
    "\n",
    "    # Create probability matrix for channels\n",
    "    channel_probs = np.zeros((n, 4))  # Online, Branch, Mobile, Partner\n",
    "\n",
    "    # Set default probabilities\n",
    "    channel_probs[:, 0] = 0.4  # Online\n",
    "    channel_probs[:, 1] = 0.3  # Branch\n",
    "    channel_probs[:, 2] = 0.2  # Mobile\n",
    "    channel_probs[:, 3] = 0.1  # Partner\n",
    "\n",
    "    # Adjust for young small loans\n",
    "    channel_probs[young_small_loan, 0] = 0.6\n",
    "    channel_probs[young_small_loan, 1] = 0.1\n",
    "    channel_probs[young_small_loan, 2] = 0.25\n",
    "    channel_probs[young_small_loan, 3] = 0.05\n",
    "\n",
    "    # Adjust for large loans\n",
    "    channel_probs[large_loan, 0] = 0.2\n",
    "    channel_probs[large_loan, 1] = 0.6\n",
    "    channel_probs[large_loan, 2] = 0.1\n",
    "    channel_probs[large_loan, 3] = 0.1\n",
    "\n",
    "    # Generate channels using vectorized choice\n",
    "    channels = np.array(['Online', 'Branch', 'Mobile', 'Partner'])[\n",
    "        np.array([np.random.choice(4, p=probs) for probs in channel_probs])\n",
    "    ]\n",
    "\n",
    "    # Vectorized purposes\n",
    "    purposes = np.where(\n",
    "        product_types == 'Personal Loan',\n",
    "        np.random.choice(['Debt Consolidation', 'Home Improvement', 'Medical',\n",
    "                         'Major Purchase', 'Other'], size=n),\n",
    "        np.where(\n",
    "            product_types == 'Business Loan',\n",
    "            np.random.choice(['Working Capital', 'Equipment', 'Expansion',\n",
    "                            'Inventory', 'Other'], size=n),\n",
    "            product_types\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Vectorized dates\n",
    "    current_time = pd.Timestamp.now()\n",
    "    app_dates = pd.to_datetime([\n",
    "        fake.date_time_between(start_date='-2y', end_date='now')\n",
    "        for _ in range(n)\n",
    "    ])\n",
    "\n",
    "    # Vectorized approval logic\n",
    "    approval_probs = np.select(\n",
    "        [\n",
    "            has_employment & (person_sample['credit_score'] > 650),\n",
    "            has_employment & (person_sample['credit_score'] > 600),\n",
    "            has_employment\n",
    "        ],\n",
    "        [0.8, 0.6, 0.3],\n",
    "        default=0.1\n",
    "    )\n",
    "\n",
    "    decisions = np.random.random(n) < approval_probs\n",
    "    decision_status = np.where(decisions, 'Approved', 'Declined')\n",
    "\n",
    "    # Vectorized approved amounts\n",
    "    approved_amounts = np.where(\n",
    "        decisions,\n",
    "        np.where(\n",
    "            person_sample['credit_score'] < 650,\n",
    "            requested_amounts * np.random.uniform(0.7, 0.9, n),\n",
    "            requested_amounts * np.random.uniform(0.9, 1.0, n)\n",
    "        ),\n",
    "        0\n",
    "    )\n",
    "\n",
    "    # Vectorized date calculations\n",
    "    decision_dates = app_dates + pd.to_timedelta(np.random.randint(1, 10, n), unit='D')\n",
    "    funding_dates = np.where(\n",
    "        decisions,\n",
    "        decision_dates + pd.to_timedelta(np.random.randint(1, 15, n), unit='D'),\n",
    "        pd.NaT\n",
    "    )\n",
    "\n",
    "    # Vectorized decline reasons\n",
    "    decline_reasons = np.select(\n",
    "        [\n",
    "            ~decisions & (person_sample['credit_score'] < 600),\n",
    "            ~decisions & ~has_employment,\n",
    "            ~decisions & (person_sample['annual_income'] < 30000),\n",
    "            ~decisions\n",
    "        ],\n",
    "        ['Low Credit Score', 'No Employment', 'Insufficient Income', 'Credit Policy'],\n",
    "        default=None\n",
    "    )\n",
    "\n",
    "    # Pre-generate all IDs at once\n",
    "    uw_ids = [f\"UW{np.random.randint(1000, 9999)}\" for _ in range(n)]\n",
    "    br_ids = np.where(channels == 'Branch',\n",
    "                      [f\"BR{np.random.randint(100, 999)}\" for _ in range(n)],\n",
    "                      None)\n",
    "    mkt_mask = np.random.random(n) < 0.3\n",
    "    mkt_ids = np.where(mkt_mask,\n",
    "                       [f\"MKT{np.random.randint(1000, 9999)}\" for _ in range(n)],\n",
    "                       None)\n",
    "\n",
    "    # Create DataFrame all at once\n",
    "    return pd.DataFrame({\n",
    "        'appid': np.arange(1, n + 1),\n",
    "        'personid': person_sample['personid'].values,\n",
    "        'product_type': product_types,\n",
    "        'requested_amount': requested_amounts.round(2),\n",
    "        'approved_amount': approved_amounts.round(2),\n",
    "        'term_months': term_months,\n",
    "        'interest_rate': interest_rates.round(3),\n",
    "        'application_date': app_dates,\n",
    "        'decision_date': decision_dates,\n",
    "        'funding_date': funding_dates,\n",
    "        'application_status': 'Completed',\n",
    "        'decision_status': decision_status,\n",
    "        'channel': channels,\n",
    "        'purpose': purposes,\n",
    "        'has_coborrower': np.random.choice([True, False], size=n, p=[0.1, 0.9]),\n",
    "        'has_collateral': np.isin(product_types, ['Mortgage', 'Auto Loan', 'Business Loan']),\n",
    "        'application_score': np.random.randint(300, 850, n),\n",
    "        'approval_probability': approval_probs,\n",
    "        'decline_reasons': decline_reasons,\n",
    "        'underwriter_id': uw_ids,\n",
    "        'branch_id': br_ids,\n",
    "        'marketing_campaign_id': mkt_ids,\n",
    "        'referral_source': np.random.choice(['Direct', 'Referral', 'Advertisement', 'Partner'],\n",
    "                                          size=n, p=[0.6, 0.2, 0.15, 0.05]),\n",
    "        'created_at': app_dates,\n",
    "        'updated_at': decision_dates\n",
    "    })\n",
    "\n",
    "def generate_application_financial(n, applications_df, persons_df, employment_df):\n",
    "    \"\"\"Generate detailed financial information for each application - FULLY FIXED\"\"\"\n",
    "\n",
    "    # Create merged dataframe for efficient access\n",
    "    merged_df = applications_df.merge(persons_df, on='personid', how='left')\n",
    "\n",
    "    # Get current employment information\n",
    "    current_employment = employment_df[employment_df['is_current'] == True].set_index('personid')\n",
    "\n",
    "    # Vectorized employment data extraction\n",
    "    has_employment = merged_df['personid'].isin(current_employment.index).values\n",
    "    monthly_employment_income = np.zeros(n)\n",
    "    employment_stability = np.zeros(n)\n",
    "\n",
    "    # Extract employment data in bulk\n",
    "    employed_persons = merged_df['personid'][has_employment].values\n",
    "    for idx, person_id in enumerate(employed_persons):\n",
    "        if person_id in current_employment.index:\n",
    "            emp = current_employment.loc[person_id]\n",
    "            if isinstance(emp, pd.DataFrame):\n",
    "                emp = emp.iloc[0]\n",
    "            pos = np.where(merged_df['personid'] == person_id)[0][0]\n",
    "            monthly_employment_income[pos] = emp['monthly_salary']\n",
    "            employment_stability[pos] = EMPLOYMENT_SECTORS[emp['employer_industry']]['stability']\n",
    "\n",
    "    annual_employment_income = monthly_employment_income * 12\n",
    "\n",
    "    # Vectorized other income calculation\n",
    "    has_other_income = np.random.random(n) < 0.3\n",
    "    other_income_types = np.where(\n",
    "        has_other_income,\n",
    "        np.random.choice(['Investment', 'Rental', 'Side Business', 'Alimony', 'Other'], size=n),\n",
    "        None\n",
    "    )\n",
    "\n",
    "    # FIXED: Handle potential NaN or negative values\n",
    "    base_income = merged_df['annual_income'].fillna(50000).values\n",
    "    other_income_amount = np.where(\n",
    "        has_other_income,\n",
    "        np.random.exponential(np.maximum(base_income * 0.1, 1000)),\n",
    "        0\n",
    "    )\n",
    "\n",
    "    total_annual_income = annual_employment_income + other_income_amount\n",
    "    total_monthly_income = total_annual_income / 12\n",
    "\n",
    "    # Ensure no zero or negative values for income\n",
    "    total_monthly_income = np.maximum(total_monthly_income, 1000)\n",
    "\n",
    "    # Vectorized asset calculations\n",
    "    age_values = merged_df['age'].fillna(30).values\n",
    "    credit_scores = merged_df['credit_score'].fillna(650).values\n",
    "\n",
    "    asset_multiplier = 0.1 + (age_values - 18) / 100 + credit_scores / 1000\n",
    "    total_assets = total_annual_income * asset_multiplier * np.random.uniform(0.5, 2.0, n)\n",
    "    liquid_assets = total_assets * np.random.uniform(0.2, 0.6, n)\n",
    "\n",
    "    # Vectorized retirement assets\n",
    "    retirement_assets = np.select(\n",
    "        [\n",
    "            age_values < 30,\n",
    "            age_values < 50,\n",
    "            age_values >= 50\n",
    "        ],\n",
    "        [\n",
    "            total_annual_income * np.random.uniform(0, 0.5, n),\n",
    "            total_annual_income * np.random.uniform(0.5, 3, n),\n",
    "            total_annual_income * np.random.uniform(2, 10, n)\n",
    "        ],\n",
    "        default=0\n",
    "    )\n",
    "\n",
    "    # FIXED: Handle home ownership with fillna\n",
    "    home_ownership = merged_df['home_ownership'].fillna('Rent').values\n",
    "    mortgage_mask = home_ownership == 'Mortgage'\n",
    "\n",
    "    mortgage_debt = np.where(\n",
    "        mortgage_mask,\n",
    "        total_annual_income * np.random.uniform(1, 4, n),\n",
    "        0\n",
    "    )\n",
    "    mortgage_payment = np.where(mortgage_mask, mortgage_debt / (30 * 12), 0)\n",
    "\n",
    "    credit_card_debt = total_annual_income * np.random.uniform(0, 0.3, n)\n",
    "\n",
    "    auto_loan_mask = np.random.random(n) < 0.5\n",
    "    auto_loan_debt = np.where(\n",
    "        auto_loan_mask,\n",
    "        total_annual_income * np.random.uniform(0, 0.4, n),\n",
    "        0\n",
    "    )\n",
    "\n",
    "    # FIXED: Handle education level with fillna\n",
    "    education_level = merged_df['education_level'].fillna('High School').values\n",
    "    student_loan_mask = (age_values < 40) & (education_level != 'High School')\n",
    "    student_loan_debt = np.where(\n",
    "        student_loan_mask,\n",
    "        total_annual_income * np.random.uniform(0, 0.5, n),\n",
    "        0\n",
    "    )\n",
    "\n",
    "    other_debt = total_annual_income * np.random.uniform(0, 0.2, n)\n",
    "    total_debt = mortgage_debt + credit_card_debt + auto_loan_debt + student_loan_debt + other_debt\n",
    "\n",
    "    # Vectorized monthly payments\n",
    "    credit_card_payment = credit_card_debt * 0.03\n",
    "    auto_loan_payment = np.where(auto_loan_debt > 0, auto_loan_debt / 60, 0)\n",
    "    student_loan_payment = np.where(student_loan_debt > 0, student_loan_debt / 120, 0)\n",
    "    other_debt_payment = np.where(other_debt > 0, other_debt / 36, 0)\n",
    "\n",
    "    total_monthly_debt_payments = (\n",
    "        mortgage_payment + credit_card_payment +\n",
    "        auto_loan_payment + student_loan_payment +\n",
    "        other_debt_payment\n",
    "    )\n",
    "\n",
    "    # FIXED: Safe division for DTI ratio\n",
    "    dti_ratio = np.where(\n",
    "        (total_monthly_income > 0) & np.isfinite(total_monthly_income),\n",
    "        np.minimum(total_monthly_debt_payments / total_monthly_income, 0.99),\n",
    "        0.99\n",
    "    )\n",
    "\n",
    "    # Vectorized expense calculations\n",
    "    housing_expense = np.where(\n",
    "        mortgage_mask,\n",
    "        mortgage_payment,\n",
    "        total_monthly_income * np.random.uniform(0.2, 0.35, n)\n",
    "    )\n",
    "\n",
    "    utilities_expense = np.random.uniform(150, 400, n)\n",
    "    transportation_expense = auto_loan_payment + np.random.uniform(100, 300, n)\n",
    "    food_expense = np.random.uniform(300, 800, n)\n",
    "    insurance_expense = np.random.uniform(100, 500, n)\n",
    "    other_expenses = np.random.uniform(200, 1000, n)\n",
    "\n",
    "    total_monthly_expenses = (\n",
    "        housing_expense + utilities_expense + transportation_expense +\n",
    "        food_expense + insurance_expense + other_expenses\n",
    "    )\n",
    "\n",
    "    # FIXED: Safe division for housing expense ratio\n",
    "    housing_expense_ratio = np.where(\n",
    "        (total_monthly_income > 0) & np.isfinite(total_monthly_income),\n",
    "        np.minimum(housing_expense / total_monthly_income, 0.99),\n",
    "        0.99\n",
    "    )\n",
    "\n",
    "    disposable_income = total_monthly_income - total_monthly_expenses - total_monthly_debt_payments\n",
    "\n",
    "    # FIXED: Safe division for savings rate\n",
    "    savings_rate = np.where(\n",
    "        (total_monthly_income > 0) & np.isfinite(total_monthly_income),\n",
    "        np.clip(disposable_income / total_monthly_income, -1, 1),\n",
    "        0\n",
    "    )\n",
    "\n",
    "    # Vectorized flags\n",
    "    bankruptcy_flag = np.random.random(n) < (0.05 * np.where(dti_ratio > 0.5, 2, 1))\n",
    "\n",
    "    # FIXED: Safe comparison for credit scores\n",
    "    credit_score_values = merged_df['credit_score'].fillna(650).values\n",
    "    default_history = np.random.random(n) < (0.1 * np.where(credit_score_values < 600, 2, 1))\n",
    "\n",
    "    # Vectorized verification statuses\n",
    "    income_verified = np.random.choice([True, False], size=n, p=[0.8, 0.2])\n",
    "    assets_verified = np.random.choice([True, False], size=n, p=[0.7, 0.3])\n",
    "    employment_verified = np.random.choice([True, False], size=n, p=[0.85, 0.15])\n",
    "\n",
    "    # Create DataFrame\n",
    "    return pd.DataFrame({\n",
    "        'financial_id': np.arange(1, n + 1),\n",
    "        'appid': applications_df['appid'],\n",
    "        'personid': applications_df['personid'],\n",
    "\n",
    "        # Income\n",
    "        'employment_income': annual_employment_income.round(2),\n",
    "        'other_income': other_income_amount.round(2),\n",
    "        'other_income_type': other_income_types,\n",
    "        'total_annual_income': total_annual_income.round(2),\n",
    "        'total_monthly_income': total_monthly_income.round(2),\n",
    "\n",
    "        # Assets\n",
    "        'total_assets': total_assets.round(2),\n",
    "        'liquid_assets': liquid_assets.round(2),\n",
    "        'retirement_assets': retirement_assets.round(2),\n",
    "        'real_estate_assets': (total_assets - liquid_assets - retirement_assets).round(2),\n",
    "\n",
    "        # Debts\n",
    "        'mortgage_debt': mortgage_debt.round(2),\n",
    "        'credit_card_debt': credit_card_debt.round(2),\n",
    "        'auto_loan_debt': auto_loan_debt.round(2),\n",
    "        'student_loan_debt': student_loan_debt.round(2),\n",
    "        'other_debt': other_debt.round(2),\n",
    "        'total_debt': total_debt.round(2),\n",
    "\n",
    "        # Monthly payments\n",
    "        'mortgage_payment': mortgage_payment.round(2),\n",
    "        'credit_card_payment': credit_card_payment.round(2),\n",
    "        'auto_loan_payment': auto_loan_payment.round(2),\n",
    "        'student_loan_payment': student_loan_payment.round(2),\n",
    "        'other_debt_payment': other_debt_payment.round(2),\n",
    "        'total_monthly_debt_payments': total_monthly_debt_payments.round(2),\n",
    "\n",
    "        # Expenses\n",
    "        'housing_expense': housing_expense.round(2),\n",
    "        'utilities_expense': utilities_expense.round(2),\n",
    "        'transportation_expense': transportation_expense.round(2),\n",
    "        'food_expense': food_expense.round(2),\n",
    "        'insurance_expense': insurance_expense.round(2),\n",
    "        'other_expenses': other_expenses.round(2),\n",
    "        'total_monthly_expenses': total_monthly_expenses.round(2),\n",
    "\n",
    "        # Ratios and flags\n",
    "        'debt_to_income_ratio': dti_ratio.round(3),\n",
    "        'housing_expense_ratio': housing_expense_ratio.round(3),\n",
    "        'disposable_income': disposable_income.round(2),\n",
    "        'savings_rate': savings_rate.round(3),\n",
    "        'bankruptcy_flag': bankruptcy_flag,\n",
    "        'default_history': default_history,\n",
    "        'employment_stability_score': employment_stability,\n",
    "\n",
    "        # Verification status\n",
    "        'income_verified': income_verified,\n",
    "        'assets_verified': assets_verified,\n",
    "        'employment_verified': employment_verified,\n",
    "\n",
    "        'financial_date': applications_df['application_date'],\n",
    "        'created_at': applications_df['application_date'],\n",
    "        'updated_at': applications_df['application_date'] + pd.to_timedelta(np.random.randint(1, 7, n), unit='D')\n",
    "    })\n",
    "\n",
    "def generate_credit_scoring(n, applications_df, persons_df, financial_df):\n",
    "    \"\"\"Generate comprehensive credit scoring data - OPTIMIZED\"\"\"\n",
    "\n",
    "    # Pre-merge dataframes to avoid repeated lookups\n",
    "    merged_app_person = applications_df.merge(persons_df, on='personid', how='left')\n",
    "    merged_app_financial = applications_df.merge(financial_df, on='appid', how='left')\n",
    "\n",
    "    # Extract arrays for vectorized operations\n",
    "    base_credit_scores = merged_app_person['credit_score'].values\n",
    "    ages = merged_app_person['age'].values\n",
    "    total_debts = merged_app_financial['total_debt'].values\n",
    "    credit_card_debts = merged_app_financial['credit_card_debt'].values\n",
    "    employment_stability = merged_app_financial['employment_stability_score'].values\n",
    "    dti_ratios = merged_app_financial['debt_to_income_ratio'].values\n",
    "    requested_amounts = applications_df['requested_amount'].values\n",
    "    has_collateral = applications_df['has_collateral'].values\n",
    "    product_types = applications_df['product_type'].values\n",
    "    app_dates = applications_df['application_date'].values\n",
    "\n",
    "    # Vectorized bureau information\n",
    "    bureau_names = np.random.choice(['Equifax', 'Experian', 'TransUnion'], size=n)\n",
    "    bureau_scores = np.clip(base_credit_scores + np.random.randint(-20, 21, n), 300, 850)\n",
    "\n",
    "    # Fixed vectorized credit history calculations\n",
    "    credit_history_length = np.zeros(n, dtype=int)\n",
    "\n",
    "    # For ages < 21\n",
    "    young_mask = ages < 21\n",
    "    credit_history_length[young_mask] = np.random.randint(0, 3, np.sum(young_mask))\n",
    "\n",
    "    # For ages >= 21\n",
    "    adult_mask = ~young_mask\n",
    "    min_history = np.maximum(0, (ages[adult_mask] - 18) // 2)\n",
    "    max_history = ages[adult_mask] - 18\n",
    "\n",
    "    # Ensure min is always less than max\n",
    "    valid_range_mask = min_history < max_history\n",
    "\n",
    "    # For cases where min < max, generate random values\n",
    "    credit_history_length[adult_mask][valid_range_mask] = np.array([\n",
    "        np.random.randint(min_val, max_val)\n",
    "        for min_val, max_val in zip(min_history[valid_range_mask], max_history[valid_range_mask])\n",
    "    ])\n",
    "\n",
    "    # For cases where min >= max, use min value\n",
    "    credit_history_length[adult_mask][~valid_range_mask] = min_history[~valid_range_mask]\n",
    "\n",
    "    total_accounts = np.where(\n",
    "        ages < 21,\n",
    "        np.random.randint(0, 5, n),\n",
    "        np.random.poisson(credit_history_length * 0.7)\n",
    "    )\n",
    "\n",
    "    open_accounts = (total_accounts * np.random.uniform(0.5, 0.9, n)).astype(int)\n",
    "    closed_accounts = total_accounts - open_accounts\n",
    "\n",
    "    # Vectorized delinquency information\n",
    "    delinquent_accounts = np.zeros(n, dtype=int)\n",
    "    collections_count = np.zeros(n, dtype=int)\n",
    "    bankruptcies_count = np.zeros(n, dtype=int)\n",
    "    max_delinquency = np.zeros(n, dtype=int)\n",
    "\n",
    "    # High credit score (>700)\n",
    "    high_score_mask = base_credit_scores > 700\n",
    "\n",
    "    # Medium credit score (650-700)\n",
    "    med_score_mask = (base_credit_scores > 650) & (base_credit_scores <= 700)\n",
    "    delinquent_accounts[med_score_mask] = np.random.choice([0, 1], size=np.sum(med_score_mask), p=[0.9, 0.1])\n",
    "    collections_count[med_score_mask] = np.random.choice([0, 1], size=np.sum(med_score_mask), p=[0.95, 0.05])\n",
    "    max_delinquency[med_score_mask] = np.random.choice([0, 30, 60], size=np.sum(med_score_mask), p=[0.8, 0.15, 0.05])\n",
    "\n",
    "    # Low credit score (<=650)\n",
    "    low_score_mask = base_credit_scores <= 650\n",
    "    delinquent_accounts[low_score_mask] = np.random.poisson(0.5, np.sum(low_score_mask))\n",
    "    collections_count[low_score_mask] = np.random.poisson(0.3, np.sum(low_score_mask))\n",
    "    bankruptcies_count[low_score_mask] = np.random.choice([0, 1], size=np.sum(low_score_mask), p=[0.9, 0.1])\n",
    "    max_delinquency[low_score_mask] = np.random.choice([0, 30, 60, 90, 120], size=np.sum(low_score_mask), p=[0.5, 0.2, 0.15, 0.1, 0.05])\n",
    "\n",
    "    # Vectorized credit utilization\n",
    "    credit_utilization = np.where(\n",
    "        total_debts > 0,\n",
    "        np.minimum(credit_card_debts / (total_debts * 0.3), 1.0),\n",
    "        0\n",
    "    )\n",
    "\n",
    "    # Vectorized payment history\n",
    "    on_time_payments = np.where(\n",
    "        delinquent_accounts == 0,\n",
    "        total_accounts * 12 * np.minimum(credit_history_length, 7),\n",
    "        (total_accounts * 12 * np.minimum(credit_history_length, 7) * np.random.uniform(0.7, 0.95, n)).astype(int)\n",
    "    )\n",
    "\n",
    "    late_payments = np.where(\n",
    "        delinquent_accounts == 0,\n",
    "        0,\n",
    "        (total_accounts * 12 * np.minimum(credit_history_length, 7) - on_time_payments).astype(int)\n",
    "    )\n",
    "\n",
    "    # Vectorized recent inquiries\n",
    "    recent_inquiries = np.where(\n",
    "        product_types == 'Credit Card',\n",
    "        np.random.poisson(2, n),\n",
    "        np.random.poisson(1, n)\n",
    "    )\n",
    "\n",
    "    # Vectorized risk assessment\n",
    "    risk_scores = np.full(n, 100)\n",
    "    risk_factors = [[] for _ in range(n)]\n",
    "\n",
    "    # Apply credit score penalties\n",
    "    low_credit_mask = base_credit_scores < 600\n",
    "    fair_credit_mask = (base_credit_scores >= 600) & (base_credit_scores < 650)\n",
    "\n",
    "    risk_scores[low_credit_mask] -= 30\n",
    "    risk_scores[fair_credit_mask] -= 15\n",
    "\n",
    "    # Apply DTI penalties\n",
    "    high_dti_mask = dti_ratios > 0.43\n",
    "    elevated_dti_mask = (dti_ratios > 0.36) & (dti_ratios <= 0.43)\n",
    "\n",
    "    risk_scores[high_dti_mask] -= 20\n",
    "    risk_scores[elevated_dti_mask] -= 10\n",
    "\n",
    "    # Apply employment stability penalties\n",
    "    low_stability_mask = employment_stability < 0.7\n",
    "    risk_scores[low_stability_mask] -= 15\n",
    "\n",
    "    # Apply payment history penalties\n",
    "    late_payment_mask = late_payments > 0\n",
    "    risk_scores[late_payment_mask] -= 20\n",
    "\n",
    "    # Apply bankruptcy penalties\n",
    "    bankruptcy_mask = bankruptcies_count > 0\n",
    "    risk_scores[bankruptcy_mask] -= 40\n",
    "\n",
    "    # Calculate application scores\n",
    "    application_scores = (\n",
    "        0.4 * base_credit_scores +\n",
    "        0.3 * (100 - dti_ratios * 100) +\n",
    "        0.2 * employment_stability * 100 +\n",
    "        0.1 * risk_scores\n",
    "    ).astype(int)\n",
    "\n",
    "    # Vectorized fraud scoring\n",
    "    fraud_indicators = (\n",
    "        (recent_inquiries > 5).astype(int) +\n",
    "        (merged_app_person['years_at_address'] < 1).astype(int) +\n",
    "        (~merged_app_financial['income_verified']).astype(int) +\n",
    "        (requested_amounts > merged_app_person['annual_income']).astype(int)\n",
    "    )\n",
    "\n",
    "    fraud_scores = np.minimum(1000, fraud_indicators * 200 + np.random.exponential(50, n))\n",
    "\n",
    "    # Vectorized probability of default\n",
    "    pd_base = np.full(n, 0.05)\n",
    "    pd_base[base_credit_scores < 600] *= 4\n",
    "    pd_base[(base_credit_scores >= 600) & (base_credit_scores < 650)] *= 2\n",
    "    pd_base[dti_ratios > 0.43] *= 2\n",
    "    pd_base[delinquent_accounts > 0] *= 1.5\n",
    "\n",
    "    probability_default = np.minimum(1.0, pd_base * np.random.uniform(0.8, 1.2, n))\n",
    "\n",
    "    # Vectorized loss given default\n",
    "    lgd = np.where(\n",
    "        has_collateral,\n",
    "        np.random.beta(2, 8, n),  # Mean around 0.2\n",
    "        np.random.beta(6, 4, n)   # Mean around 0.6\n",
    "    )\n",
    "\n",
    "    # Expected loss calculation\n",
    "    ead = requested_amounts\n",
    "    expected_loss = ead * probability_default * lgd\n",
    "\n",
    "    # Vectorized verification statuses\n",
    "    identity_verification = np.random.choice(['Verified', 'Pending', 'Failed'], size=n, p=[0.9, 0.08, 0.02])\n",
    "\n",
    "    # Vectorized recommendations\n",
    "    recommendations = np.where(\n",
    "        (application_scores > 650) & (risk_scores > 60) & (fraud_scores < 500),\n",
    "        'Approve',\n",
    "        'Decline'\n",
    "    )\n",
    "\n",
    "    confidence_scores = np.random.uniform(0.7, 0.99, n)\n",
    "\n",
    "    # Create risk factors strings\n",
    "    risk_factors_list = []\n",
    "    for i in range(n):\n",
    "        factors = []\n",
    "        if base_credit_scores[i] < 600:\n",
    "            factors.append('Low Credit Score')\n",
    "        elif base_credit_scores[i] < 650:\n",
    "            factors.append('Fair Credit Score')\n",
    "\n",
    "        if dti_ratios[i] > 0.43:\n",
    "            factors.append('High Debt-to-Income Ratio')\n",
    "        elif dti_ratios[i] > 0.36:\n",
    "            factors.append('Elevated Debt-to-Income Ratio')\n",
    "\n",
    "        if employment_stability[i] < 0.7:\n",
    "            factors.append('Employment Instability')\n",
    "\n",
    "        if late_payments[i] > 0:\n",
    "            factors.append('Payment History Issues')\n",
    "\n",
    "        if bankruptcies_count[i] > 0:\n",
    "            factors.append('Prior Bankruptcy')\n",
    "\n",
    "        risk_factors_list.append(','.join(factors) if factors else None)\n",
    "\n",
    "    # Vectorized dates\n",
    "    credit_report_dates = pd.to_datetime(app_dates) - pd.to_timedelta(np.random.randint(1, 30, n), unit='D')\n",
    "    score_dates = pd.to_datetime(app_dates)\n",
    "    created_dates = pd.to_datetime(app_dates)\n",
    "    updated_dates = pd.to_datetime(app_dates) + pd.to_timedelta(np.random.randint(1, 24, n), unit='h')\n",
    "\n",
    "    # Create DataFrame\n",
    "    return pd.DataFrame({\n",
    "        'scoring_id': np.arange(1, n + 1),\n",
    "        'appid': applications_df['appid'],\n",
    "        'personid': applications_df['personid'],\n",
    "\n",
    "        # Credit bureau information\n",
    "        'bureau_name': bureau_names,\n",
    "        'bureau_score': bureau_scores,\n",
    "        'credit_score': base_credit_scores,\n",
    "        'credit_report_date': credit_report_dates,\n",
    "\n",
    "        # Credit history\n",
    "        'credit_history_length_months': credit_history_length * 12,\n",
    "        'total_accounts': total_accounts,\n",
    "        'open_accounts': open_accounts,\n",
    "        'closed_accounts': closed_accounts,\n",
    "        'delinquent_accounts': delinquent_accounts,\n",
    "        'collections_count': collections_count,\n",
    "        'bankruptcies_count': bankruptcies_count,\n",
    "        'foreclosures_count': np.where(base_credit_scores > 600, 0,\n",
    "                                      np.random.choice([0, 1], size=n, p=[0.95, 0.05])),\n",
    "\n",
    "        # Credit utilization\n",
    "        'total_credit_limit': np.where(credit_utilization > 0,\n",
    "                                      total_debts / credit_utilization,\n",
    "                                      merged_app_financial['total_annual_income'] * 0.5).round(2),\n",
    "        'total_credit_balance': total_debts.round(2),\n",
    "        'credit_utilization_ratio': credit_utilization.round(3),\n",
    "\n",
    "        # Payment history\n",
    "        'on_time_payments': on_time_payments,\n",
    "        'late_payments': late_payments,\n",
    "        'missed_payments': (late_payments * 0.2).astype(int),\n",
    "        'max_delinquency_days': max_delinquency,\n",
    "\n",
    "        # Recent activity\n",
    "        'recent_inquiries_6m': recent_inquiries,\n",
    "        'new_accounts_6m': np.random.poisson(0.5, n),\n",
    "        'recent_balance_increase': np.random.choice([True, False], size=n, p=[0.3, 0.7]),\n",
    "\n",
    "        # Risk assessment\n",
    "        'application_score': application_scores,\n",
    "        'risk_score': risk_scores,\n",
    "        'risk_factors': risk_factors_list,\n",
    "        'fraud_score': fraud_scores.astype(int),\n",
    "        'fraud_flags': fraud_indicators,\n",
    "\n",
    "        # Probability metrics\n",
    "        'probability_default': probability_default.round(4),\n",
    "        'loss_given_default': lgd.round(4),\n",
    "        'exposure_at_default': ead.round(2),\n",
    "        'expected_loss': expected_loss.round(2),\n",
    "\n",
    "        # Verification scores\n",
    "        'income_verification_status': np.where(merged_app_financial['income_verified'],\n",
    "                                              'Verified', 'Unverified'),\n",
    "        'employment_verification_status': np.where(merged_app_financial['employment_verified'],\n",
    "                                                  'Verified', 'Unverified'),\n",
    "        'identity_verification_status': identity_verification,\n",
    "\n",
    "        # Decision recommendation\n",
    "        'recommendation': recommendations,\n",
    "        'confidence_score': confidence_scores.round(3),\n",
    "\n",
    "        'score_date': score_dates,\n",
    "        'created_at': created_dates,\n",
    "        'updated_at': updated_dates\n",
    "    })\n",
    "\n",
    "def generate_loans(n, applications_df):\n",
    "    \"\"\"Generate loan records with guaranteed output - OPTIMIZED\"\"\"\n",
    "    # Create copies to avoid modifying original data\n",
    "    apps = applications_df.copy()\n",
    "\n",
    "    # Check if we have any approved applications already\n",
    "    decision_column = None\n",
    "    for col in ['decision_status', 'status', 'application_status']:\n",
    "        if col in apps.columns:\n",
    "            decision_column = col\n",
    "            break\n",
    "\n",
    "    if decision_column:\n",
    "        approved_apps = apps[apps[decision_column] == 'Approved']\n",
    "    else:\n",
    "        approved_apps = pd.DataFrame()\n",
    "\n",
    "    # If no approved applications, create them\n",
    "    if len(approved_apps) == 0:\n",
    "        # Take a sample of applications and mark them as approved\n",
    "        if len(apps) > 0:\n",
    "            sample_size = min(n, len(apps))\n",
    "            approved_apps = apps.sample(sample_size).copy()\n",
    "            approved_apps['decision_status'] = 'Approved'\n",
    "\n",
    "            if 'approved_amount' not in approved_apps.columns:\n",
    "                if 'requested_amount' in approved_apps.columns:\n",
    "                    approved_apps['approved_amount'] = approved_apps['requested_amount']\n",
    "                else:\n",
    "                    approved_apps['approved_amount'] = np.random.uniform(10000, 100000, len(approved_apps))\n",
    "        else:\n",
    "            # Create synthetic approved applications\n",
    "            approved_apps = pd.DataFrame({\n",
    "                'appid': range(1, n + 1),\n",
    "                'personid': np.random.randint(1, 1000, n),\n",
    "                'product_type': np.random.choice(['Personal Loan', 'Auto Loan', 'Mortgage', 'Business Loan'], n),\n",
    "                'requested_amount': np.random.uniform(10000, 100000, n),\n",
    "                'approved_amount': np.random.uniform(10000, 100000, n),\n",
    "                'term_months': np.random.choice([12, 24, 36, 48, 60], n),\n",
    "                'interest_rate': np.random.uniform(5, 15, n),\n",
    "                'application_date': pd.date_range(end=datetime.now(), periods=n, freq='-1D')[::-1],\n",
    "                'decision_status': 'Approved',\n",
    "                'channel': np.random.choice(['Online', 'Branch', 'Mobile'], n),\n",
    "                'purpose': np.random.choice(['Home Improvement', 'Debt Consolidation', 'Major Purchase'], n)\n",
    "            })\n",
    "\n",
    "    # Limit to requested number\n",
    "    approved_apps = approved_apps.head(n).reset_index(drop=True)\n",
    "\n",
    "    # Generate loan details using vectorized operations\n",
    "    current_date = datetime.now()\n",
    "    n_loans = len(approved_apps)\n",
    "\n",
    "    # Extract and prepare data columns\n",
    "    approved_amounts = approved_apps['approved_amount'].values if 'approved_amount' in approved_apps.columns else \\\n",
    "                      approved_apps['requested_amount'].values if 'requested_amount' in approved_apps.columns else \\\n",
    "                      np.random.uniform(10000, 100000, n_loans)\n",
    "\n",
    "    app_dates = pd.to_datetime(approved_apps['application_date']) if 'application_date' in approved_apps.columns else \\\n",
    "                current_date - pd.to_timedelta(np.random.randint(30, 365, n_loans), unit='D')\n",
    "\n",
    "    term_months = approved_apps['term_months'].values if 'term_months' in approved_apps.columns else \\\n",
    "                  np.random.choice([12, 24, 36, 48, 60], n_loans)\n",
    "\n",
    "    interest_rates = approved_apps['interest_rate'].values if 'interest_rate' in approved_apps.columns else \\\n",
    "                     np.random.uniform(5, 15, n_loans)\n",
    "\n",
    "    # Vectorized date calculations\n",
    "    decision_dates = app_dates + pd.to_timedelta(np.random.randint(1, 10, n_loans), unit='D')\n",
    "    funding_dates = decision_dates + pd.to_timedelta(np.random.randint(1, 15, n_loans), unit='D')\n",
    "    maturity_dates = funding_dates + pd.to_timedelta(term_months * 30, unit='D')\n",
    "\n",
    "    # Calculate loan age and status\n",
    "    loan_age_days = (current_date - funding_dates).dt.days\n",
    "\n",
    "    # Vectorized loan status determination\n",
    "    loan_status = np.where(\n",
    "        loan_age_days < 0, 'Pending',\n",
    "        np.where(\n",
    "            loan_age_days < 90, 'Current',\n",
    "            np.where(\n",
    "                loan_age_days > term_months * 30, 'Paid Off',\n",
    "                np.where(\n",
    "                    np.random.random(n_loans) < 0.05,\n",
    "                    np.where(loan_age_days <= 180, 'Default', 'Charged Off'),\n",
    "                    'Current'\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Vectorized payment calculations\n",
    "    monthly_payments = np.where(term_months > 0, approved_amounts / term_months, 0)\n",
    "    payments_made = np.minimum(np.maximum(loan_age_days // 30, 0), term_months)\n",
    "\n",
    "    # Vectorized balance calculations\n",
    "    current_balances = np.where(\n",
    "        loan_status == 'Paid Off',\n",
    "        0,\n",
    "        np.maximum(approved_amounts - monthly_payments * payments_made, 0)\n",
    "    )\n",
    "\n",
    "    total_paid = np.where(\n",
    "        loan_status == 'Paid Off',\n",
    "        approved_amounts * (1 + interest_rates / 100 * term_months / 12),\n",
    "        monthly_payments * payments_made\n",
    "    )\n",
    "\n",
    "    # Vectorized days past due calculation\n",
    "    days_past_due = np.where(\n",
    "        np.isin(loan_status, ['Default', 'Charged Off']),\n",
    "        np.random.randint(30, 180, n_loans),\n",
    "        np.where(\n",
    "            (loan_status == 'Current') & (np.random.random(n_loans) < 0.1),\n",
    "            np.random.randint(1, 29, n_loans),\n",
    "            0\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Create DataFrame\n",
    "    loans_df = pd.DataFrame({\n",
    "        'loanid': np.arange(1, n_loans + 1),\n",
    "        'appid': approved_apps['appid'].values if 'appid' in approved_apps.columns else np.arange(n_loans),\n",
    "        'personid': approved_apps['personid'].values if 'personid' in approved_apps.columns else np.random.randint(1, 1000, n_loans),\n",
    "        'product_type': approved_apps['product_type'].values if 'product_type' in approved_apps.columns else 'Personal Loan',\n",
    "        'original_amount': approved_amounts.round(2),\n",
    "        'current_balance': current_balances.round(2),\n",
    "        'interest_rate': interest_rates.round(3),\n",
    "        'term_months': term_months,\n",
    "        'monthly_payment': monthly_payments.round(2),\n",
    "        'origination_date': funding_dates,\n",
    "        'maturity_date': maturity_dates,\n",
    "        'loan_status': loan_status,\n",
    "        'days_past_due': days_past_due,\n",
    "        'total_paid': total_paid.round(2),\n",
    "        'loan_purpose': approved_apps['purpose'].values if 'purpose' in approved_apps.columns else 'General',\n",
    "        'created_at': funding_dates,\n",
    "        'updated_at': current_date\n",
    "    })\n",
    "\n",
    "    return loans_df\n",
    "\n",
    "def generate_loan_payments(n, loans_df):\n",
    "    \"\"\"Generate detailed loan payment history\"\"\"\n",
    "    payments = []\n",
    "\n",
    "    for _, loan in loans_df.iterrows():\n",
    "        if loan['term_months'] == 0:  # Skip credit cards\n",
    "            continue\n",
    "\n",
    "        # Calculate payment schedule\n",
    "        loan_amount = loan['original_amount']\n",
    "        monthly_rate = loan['interest_rate'] / 100 / 12\n",
    "        num_payments = loan['term_months']\n",
    "\n",
    "        # Monthly payment calculation (PMT formula)\n",
    "        if monthly_rate > 0:\n",
    "            monthly_payment = loan_amount * (monthly_rate * (1 + monthly_rate)**num_payments) / ((1 + monthly_rate)**num_payments - 1)\n",
    "        else:\n",
    "            monthly_payment = loan_amount / num_payments\n",
    "\n",
    "        # Generate payment history\n",
    "        current_balance = loan_amount\n",
    "        loan_start = loan['origination_date']\n",
    "        current_date = datetime.now()\n",
    "\n",
    "        # Determine payment behavior pattern\n",
    "        if loan['loan_status'] in ['Default', 'Charged Off']:\n",
    "            payment_pattern = 'Delinquent'\n",
    "        elif loan['days_past_due'] > 0:\n",
    "            payment_pattern = 'Occasionally Late'\n",
    "        else:\n",
    "            payment_pattern = 'On Time'\n",
    "\n",
    "        for month in range(num_payments):\n",
    "            due_date = loan_start + timedelta(days=30 * (month + 1))\n",
    "\n",
    "            # Skip future payments\n",
    "            if due_date > current_date:\n",
    "                break\n",
    "\n",
    "            # Determine payment behavior\n",
    "            if payment_pattern == 'On Time':\n",
    "                payment_delay = np.random.choice([-5, -3, -1, 0, 1], p=[0.1, 0.2, 0.3, 0.3, 0.1])\n",
    "            elif payment_pattern == 'Occasionally Late':\n",
    "                payment_delay = np.random.choice([-3, 0, 3, 7, 15], p=[0.1, 0.4, 0.3, 0.15, 0.05])\n",
    "            else:  # Delinquent\n",
    "                if month < num_payments * 0.3:  # Early payments were okay\n",
    "                    payment_delay = np.random.choice([0, 3, 7], p=[0.6, 0.3, 0.1])\n",
    "                else:  # Later payments became problematic\n",
    "                    payment_delay = np.random.choice([15, 30, 60, 90], p=[0.2, 0.3, 0.3, 0.2])\n",
    "\n",
    "            # Convert numpy.int64 to regular Python int for timedelta\n",
    "            payment_delay = int(payment_delay)\n",
    "            payment_date = due_date + timedelta(days=payment_delay)\n",
    "\n",
    "            # Skip if payment is in the future\n",
    "            if payment_date > current_date:\n",
    "                break\n",
    "\n",
    "            # Calculate principal and interest portions\n",
    "            interest_portion = current_balance * monthly_rate\n",
    "            principal_portion = monthly_payment - interest_portion\n",
    "\n",
    "            # Simulate payment variations\n",
    "            if payment_delay > 5:\n",
    "                late_fee = monthly_payment * 0.05\n",
    "                payment_status = 'Late'\n",
    "            else:\n",
    "                late_fee = 0\n",
    "                payment_status = 'On Time'\n",
    "\n",
    "            # Sometimes partial payments\n",
    "            if payment_pattern == 'Delinquent' and month > num_payments * 0.3 and np.random.random() < 0.3:\n",
    "                actual_payment = monthly_payment * np.random.uniform(0.5, 0.9)\n",
    "                payment_status = 'Partial'\n",
    "            else:\n",
    "                actual_payment = monthly_payment + late_fee\n",
    "\n",
    "            payments.append({\n",
    "                'payment_id': len(payments) + 1,\n",
    "                'loanid': loan['loanid'],\n",
    "                'payment_date': payment_date,\n",
    "                'due_date': due_date,\n",
    "                'payment_amount': round(actual_payment, 2),\n",
    "                'principal_portion': round(principal_portion, 2),\n",
    "                'interest_portion': round(interest_portion, 2),\n",
    "                'late_fee': round(late_fee, 2),\n",
    "                'payment_method': np.random.choice(['Auto-debit', 'Transfer', 'Online', 'Check', 'Cash'],\n",
    "                                                 p=[0.5, 0.2, 0.2, 0.05, 0.05]),\n",
    "                'payment_status': payment_status,\n",
    "                'remaining_balance': round(current_balance - principal_portion, 2)\n",
    "            })\n",
    "\n",
    "            current_balance -= principal_portion\n",
    "\n",
    "            if len(payments) >= n:\n",
    "                break\n",
    "\n",
    "        if len(payments) >= n:\n",
    "            break\n",
    "\n",
    "    return pd.DataFrame(payments[:n])\n",
    "\n",
    "def generate_transactions(n, persons_df):\n",
    "    \"\"\"Generate realistic transaction patterns more efficiently\"\"\"\n",
    "    transactions = []\n",
    "    current_date = datetime.now()\n",
    "\n",
    "    # Pre-define merchant names\n",
    "    merchant_names = {\n",
    "        'Groceries': ['Walmart', 'Kroger', 'Safeway', 'Whole Foods', 'Target'],\n",
    "        'Dining': ['Starbucks', 'McDonald\\'s', 'Chipotle', 'Local Restaurant', 'Pizza Place'],\n",
    "        'Shopping': ['Amazon', 'Best Buy', 'Macy\\'s', 'Home Depot', 'Local Store'],\n",
    "        'Transportation': ['Shell', 'Chevron', 'Uber', 'Lyft', 'Transit Authority'],\n",
    "        'Utilities': ['Electric Company', 'Water Company', 'Gas Company', 'Internet Provider'],\n",
    "        'Entertainment': ['Netflix', 'AMC Theaters', 'Local Cinema', 'Concert Venue'],\n",
    "        'Healthcare': ['Local Pharmacy', 'Doctor\\'s Office', 'Hospital', 'Dental Office'],\n",
    "        'Housing': ['Mortgage Company', 'Property Management', 'HOA'],\n",
    "        'Travel': ['Airlines', 'Hotels', 'Booking.com', 'Airbnb']\n",
    "    }\n",
    "\n",
    "    # Pre-compute transaction counts by customer segment\n",
    "    segment_to_tx_count = {\n",
    "        'Elite': (40, 80),\n",
    "        'Premium': (30, 50),\n",
    "        'Standard': (20, 35),\n",
    "        'Basic': (10, 25)\n",
    "    }\n",
    "\n",
    "    essential_categories = list(TRANSACTION_PATTERNS['Essential'].keys())\n",
    "    discretionary_categories = list(TRANSACTION_PATTERNS['Discretionary'].keys())\n",
    "\n",
    "    # Process in batches for better vectorization\n",
    "    batch_size = min(1000, n)\n",
    "    remaining = n\n",
    "    transaction_id_counter = 0\n",
    "\n",
    "    # Process person by person (while keeping track of total transactions)\n",
    "    for _, person in persons_df.iterrows():\n",
    "        # Skip if we've generated enough transactions\n",
    "        if remaining <= 0:\n",
    "            break\n",
    "\n",
    "        # Determine monthly transaction count based on segment\n",
    "        segment = person['customer_segment']\n",
    "        min_tx, max_tx = segment_to_tx_count.get(segment, (10, 25))\n",
    "        monthly_transactions = np.random.randint(min_tx, max_tx)\n",
    "\n",
    "        # Calculate person's income factor once\n",
    "        income_factor = person['annual_income'] / 50000  # Normalize to median income\n",
    "        income_factor = 0.5 + 0.5 * min(income_factor, 3)\n",
    "\n",
    "        # Generate batches of transactions for this person\n",
    "        person_months = min(12, (remaining + monthly_transactions - 1) // monthly_transactions)\n",
    "\n",
    "        for month_offset in range(person_months):\n",
    "            # Skip if we've generated enough transactions\n",
    "            if remaining <= 0:\n",
    "                break\n",
    "\n",
    "            month_start = current_date - timedelta(days=30 * month_offset)\n",
    "\n",
    "            # Determine actual transaction count for this month (respect remaining count)\n",
    "            month_tx_count = min(monthly_transactions, remaining)\n",
    "            remaining -= month_tx_count\n",
    "\n",
    "            # Generate vectors for all month's transactions at once\n",
    "            # 1. Transaction dates\n",
    "            days_offset = np.random.randint(0, 30, size=month_tx_count)\n",
    "            transaction_dates = [month_start - timedelta(days=int(days)) for days in days_offset]\n",
    "\n",
    "            # 2. Categories\n",
    "            category_random = np.random.random(size=month_tx_count)\n",
    "            is_essential = category_random < 0.6\n",
    "\n",
    "            categories = np.empty(month_tx_count, dtype=object)\n",
    "            category_types = np.empty(month_tx_count, dtype=object)\n",
    "\n",
    "            # Set essential categories\n",
    "            essential_count = np.sum(is_essential)\n",
    "            if essential_count > 0:\n",
    "                essential_indices = np.random.randint(0, len(essential_categories), size=essential_count)\n",
    "                categories[is_essential] = [essential_categories[i] for i in essential_indices]\n",
    "                category_types[is_essential] = 'Essential'\n",
    "\n",
    "            # Set discretionary categories\n",
    "            discretionary_count = month_tx_count - essential_count\n",
    "            if discretionary_count > 0:\n",
    "                discretionary_indices = np.random.randint(0, len(discretionary_categories), size=discretionary_count)\n",
    "                categories[~is_essential] = [discretionary_categories[i] for i in discretionary_indices]\n",
    "                category_types[~is_essential] = 'Discretionary'\n",
    "\n",
    "            # 3. Transaction amounts\n",
    "            base_amounts = np.zeros(month_tx_count)\n",
    "            variances = np.zeros(month_tx_count)\n",
    "\n",
    "            # Calculate amounts for each category\n",
    "            for i, (cat_type, category) in enumerate(zip(category_types, categories)):\n",
    "                pattern = TRANSACTION_PATTERNS[cat_type][category]\n",
    "                min_amount, max_amount = pattern['amount_range']\n",
    "                base_amounts[i] = np.random.uniform(min_amount, max_amount)\n",
    "                variances[i] = pattern['variance']\n",
    "\n",
    "            # Apply income factor and variance\n",
    "            amounts = base_amounts * income_factor\n",
    "            variance_factors = 1 + np.random.normal(0, variances)\n",
    "            amounts = amounts * variance_factors\n",
    "            amounts = np.maximum(5, amounts)  # Minimum transaction amount\n",
    "            amounts = np.round(amounts, 2)\n",
    "\n",
    "            # 4. Transaction types\n",
    "            tx_types = np.empty(month_tx_count, dtype=object)\n",
    "            high_value_mask = amounts > 1000\n",
    "\n",
    "            # For transactions > $1000\n",
    "            high_value_count = np.sum(high_value_mask)\n",
    "            if high_value_count > 0:\n",
    "                high_value_types = np.random.choice(\n",
    "                    ['ACH', 'Wire', 'Card'],\n",
    "                    size=high_value_count,\n",
    "                    p=[0.4, 0.3, 0.3]\n",
    "                )\n",
    "                tx_types[high_value_mask] = high_value_types\n",
    "\n",
    "            # For transactions <= $1000\n",
    "            low_value_count = month_tx_count - high_value_count\n",
    "            if low_value_count > 0:\n",
    "                low_value_types = np.random.choice(\n",
    "                    ['Card', 'ACH', 'Cash'],\n",
    "                    size=low_value_count,\n",
    "                    p=[0.7, 0.2, 0.1]\n",
    "                )\n",
    "                tx_types[~high_value_mask] = low_value_types\n",
    "\n",
    "            # 5. Merchant names\n",
    "            merchant_array = np.empty(month_tx_count, dtype=object)\n",
    "            for i, category in enumerate(categories):\n",
    "                possible_merchants = merchant_names.get(category, ['Generic Merchant'])\n",
    "                merchant_array[i] = np.random.choice(possible_merchants)\n",
    "\n",
    "            # 6. Transaction status and decline reasons\n",
    "            status_random = np.random.random(size=month_tx_count)\n",
    "            statuses = np.full(month_tx_count, 'Completed', dtype=object)\n",
    "            statuses[status_random < 0.02] = 'Declined'  # 2% declined\n",
    "            statuses[np.logical_and(status_random >= 0.02, status_random < 0.03)] = 'Pending'  # 1% pending\n",
    "\n",
    "            decline_reasons = np.full(month_tx_count, None, dtype=object)\n",
    "            declined_mask = statuses == 'Declined'\n",
    "\n",
    "            if np.any(declined_mask):\n",
    "                decline_options = ['Insufficient Funds', 'Fraud Alert', 'Invalid Card']\n",
    "                decline_values = np.random.choice(decline_options, size=np.sum(declined_mask))\n",
    "                decline_reasons[declined_mask] = decline_values\n",
    "\n",
    "            # 7. Channels\n",
    "            channels = np.random.choice(\n",
    "                ['Online', 'POS', 'ATM', 'Mobile'],\n",
    "                size=month_tx_count,\n",
    "                p=[0.3, 0.4, 0.1, 0.2]\n",
    "            )\n",
    "\n",
    "            # 8. International flag\n",
    "            is_international = np.random.random(size=month_tx_count) < 0.05\n",
    "\n",
    "            # 9. Post dates (0-2 days after transaction date)\n",
    "            post_date_offsets = np.random.randint(0, 3, size=month_tx_count)\n",
    "            post_dates = [\n",
    "                tx_date + timedelta(days=int(offset))\n",
    "                for tx_date, offset in zip(transaction_dates, post_date_offsets)\n",
    "            ]\n",
    "\n",
    "            # 10. Update times (1-60 minutes after creation)\n",
    "            update_minute_offsets = np.random.randint(1, 60, size=month_tx_count)\n",
    "            updated_at_times = [\n",
    "                tx_date + timedelta(minutes=int(minutes))\n",
    "                for tx_date, minutes in zip(transaction_dates, update_minute_offsets)\n",
    "            ]\n",
    "\n",
    "            # Generate all transactions for this month\n",
    "            for i in range(month_tx_count):\n",
    "                transaction_id_counter += 1\n",
    "\n",
    "                transactions.append({\n",
    "                    'transaction_id': transaction_id_counter,\n",
    "                    'personid': person['personid'],\n",
    "                    'transaction_date': transaction_dates[i],\n",
    "                    'post_date': post_dates[i],\n",
    "                    'transaction_type': tx_types[i],\n",
    "                    'transaction_category': categories[i],\n",
    "                    'merchant_name': merchant_array[i],\n",
    "                    'merchant_category': categories[i],\n",
    "                    'amount': amounts[i],\n",
    "                    'currency': 'USD',\n",
    "                    'transaction_status': statuses[i],\n",
    "                    'decline_reason': decline_reasons[i],\n",
    "                    'channel': channels[i],\n",
    "                    'location_city': person['address_city'],\n",
    "                    'location_state': person['address_state'],\n",
    "                    'location_country': 'US',\n",
    "                    'is_international': is_international[i],\n",
    "                    'description': f\"{merchant_array[i]} - {categories[i]}\",\n",
    "                    'created_at': transaction_dates[i],\n",
    "                    'updated_at': updated_at_times[i]\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(transactions)\n",
    "\n",
    "def generate_transactions_p2p(n, persons_df):\n",
    "    \"\"\"Generate P2P transaction records more efficiently\"\"\"\n",
    "    # Constants\n",
    "    p2p_purposes = ['Rent Split', 'Dinner Split', 'Gift', 'Loan Repayment', 'Utilities Split', 'Other']\n",
    "    p2p_platforms = ['Venmo', 'Zelle', 'CashApp', 'PayPal', 'Bank Transfer']\n",
    "\n",
    "    # Pre-generate all random selections\n",
    "    person_ids = persons_df['personid'].values\n",
    "    num_persons = len(person_ids)\n",
    "\n",
    "    # Generate sender and receiver pairs ensuring they're different\n",
    "    senders_idx = np.random.randint(0, num_persons, size=n)\n",
    "    receivers_idx = np.random.randint(0, num_persons, size=n)\n",
    "\n",
    "    # Make sure senders and receivers are different people\n",
    "    same_person_mask = senders_idx == receivers_idx\n",
    "    if np.any(same_person_mask):\n",
    "        # Shift receivers who are the same as senders\n",
    "        receivers_idx[same_person_mask] = (receivers_idx[same_person_mask] + 1) % num_persons\n",
    "\n",
    "    sender_ids = person_ids[senders_idx]\n",
    "    receiver_ids = person_ids[receivers_idx]\n",
    "\n",
    "    # Pre-generate all other random values\n",
    "    current_date = datetime.now()\n",
    "\n",
    "    # Generate dates as timestamps in seconds\n",
    "    date_range_end = int(current_date.timestamp())\n",
    "    date_range_start = int((current_date - timedelta(days=365)).timestamp())\n",
    "    transaction_timestamps = np.random.randint(date_range_start, date_range_end, size=n)\n",
    "    transaction_dates = [datetime.fromtimestamp(ts) for ts in transaction_timestamps]\n",
    "\n",
    "    # Generate purposes and corresponding amounts\n",
    "    purposes = np.random.choice(p2p_purposes, size=n)\n",
    "\n",
    "    # Initialize amounts array\n",
    "    amounts = np.zeros(n)\n",
    "\n",
    "    # Set amounts based on purpose\n",
    "    rent_mask = purposes == 'Rent Split'\n",
    "    amounts[rent_mask] = np.random.uniform(300, 1500, size=np.sum(rent_mask))\n",
    "\n",
    "    dinner_mask = purposes == 'Dinner Split'\n",
    "    amounts[dinner_mask] = np.random.uniform(10, 100, size=np.sum(dinner_mask))\n",
    "\n",
    "    gift_mask = purposes == 'Gift'\n",
    "    amounts[gift_mask] = np.random.uniform(20, 500, size=np.sum(gift_mask))\n",
    "\n",
    "    # All other purposes\n",
    "    other_mask = ~(rent_mask | dinner_mask | gift_mask)\n",
    "    amounts[other_mask] = np.random.uniform(10, 1000, size=np.sum(other_mask))\n",
    "\n",
    "    # Round amounts to 2 decimal places\n",
    "    amounts = np.round(amounts, 2)\n",
    "\n",
    "    # Generate platforms\n",
    "    platforms = np.random.choice(p2p_platforms, size=n)\n",
    "\n",
    "    # Generate transaction statuses\n",
    "    random_status = np.random.random(size=n)\n",
    "    statuses = np.full(n, 'Completed', dtype=object)\n",
    "    statuses[random_status < 0.01] = 'Failed'  # 1% failed\n",
    "    statuses[np.logical_and(random_status >= 0.01, random_status < 0.06)] = 'Pending'  # 5% pending\n",
    "\n",
    "    # Generate failure reasons\n",
    "    failure_reasons = np.full(n, None, dtype=object)\n",
    "    failed_mask = statuses == 'Failed'\n",
    "    if np.any(failed_mask):\n",
    "        failure_options = ['Insufficient Funds', 'Account Closed', 'Limit Exceeded']\n",
    "        failure_reasons[failed_mask] = np.random.choice(failure_options, size=np.sum(failed_mask))\n",
    "\n",
    "    # Generate memos\n",
    "    have_memo_mask = np.random.random(size=n) < 0.7\n",
    "    memos = np.full(n, None, dtype=object)\n",
    "    if np.any(have_memo_mask):\n",
    "        memos[have_memo_mask] = [fake.sentence() for _ in range(np.sum(have_memo_mask))]\n",
    "\n",
    "    # Generate is_recurring flags\n",
    "    recurring_eligible = np.isin(purposes, ['Rent Split', 'Utilities Split'])\n",
    "    random_recurring = np.random.random(size=n) < 0.8\n",
    "    is_recurring = np.logical_and(recurring_eligible, random_recurring)\n",
    "\n",
    "    # Generate update times (1-30 minutes after creation)\n",
    "    # Convert numpy.int32 to Python int to fix the TypeError\n",
    "    update_minutes = [int(mins) for mins in np.random.randint(1, 31, size=n)]\n",
    "    updated_at = [date + timedelta(minutes=mins) for date, mins in zip(transaction_dates, update_minutes)]\n",
    "\n",
    "    # Create the dataframe in one go\n",
    "    p2p_transactions = {\n",
    "        'p2p_transaction_id': np.arange(1, n+1),\n",
    "        'sender_personid': sender_ids,\n",
    "        'receiver_personid': receiver_ids,\n",
    "        'transaction_date': transaction_dates,\n",
    "        'amount': amounts,\n",
    "        'currency': ['USD'] * n,\n",
    "        'purpose': purposes,\n",
    "        'platform': platforms,\n",
    "        'transaction_status': statuses,\n",
    "        'failure_reason': failure_reasons,\n",
    "        'memo': memos,\n",
    "        'is_recurring': is_recurring,\n",
    "        'created_at': transaction_dates,\n",
    "        'updated_at': updated_at\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(p2p_transactions)\n",
    "\n",
    "def generate_vwlob(end_date=None, loans_df=None):\n",
    "    \"\"\"Generate daily loan observation records showing only active loans for each date - OPTIMIZED\"\"\"\n",
    "\n",
    "    if loans_df is None or len(loans_df) == 0:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Use current date if no end date specified\n",
    "    if end_date is None:\n",
    "        end_date = datetime.now()\n",
    "    else:\n",
    "        end_date = pd.to_datetime(end_date)\n",
    "\n",
    "    # Convert dates to pandas datetime\n",
    "    origination_dates = pd.to_datetime(loans_df['origination_date'])\n",
    "    maturity_dates = pd.to_datetime(loans_df['maturity_date'])\n",
    "\n",
    "    # Find the earliest origination date and latest date to process\n",
    "    min_date = origination_dates.min()\n",
    "\n",
    "    # Generate all dates from earliest origination to end_date\n",
    "    all_dates = pd.date_range(start=min_date, end=end_date, freq='D')\n",
    "\n",
    "    all_records = []\n",
    "\n",
    "    # For each date, find which loans are active\n",
    "    for current_date in all_dates:\n",
    "        # A loan is active if:\n",
    "        # 1. Origination date <= current_date\n",
    "        # 2. Maturity date > current_date OR loan status is not 'Paid Off'\n",
    "        active_mask = (\n",
    "            (origination_dates <= current_date) &\n",
    "            ((maturity_dates > current_date) | (loans_df['loan_status'] != 'Paid Off'))\n",
    "        )\n",
    "\n",
    "        active_loans = loans_df[active_mask].copy()\n",
    "\n",
    "        if len(active_loans) == 0:\n",
    "            continue\n",
    "\n",
    "        # Calculate days on book for each active loan\n",
    "        days_on_book = (current_date - origination_dates[active_mask]).dt.days\n",
    "\n",
    "        # Calculate current balance for each active loan\n",
    "        daily_payment = active_loans['monthly_payment'] / 30\n",
    "        principal_paid = daily_payment * days_on_book * 0.6\n",
    "        current_balances = np.maximum(0, active_loans['original_amount'] - principal_paid)\n",
    "\n",
    "        # Calculate overdue days as of current_date\n",
    "        overdue_days = np.zeros(len(active_loans), dtype=int)\n",
    "\n",
    "        for idx, (loan_idx, loan) in enumerate(active_loans.iterrows()):\n",
    "            if loan['loan_status'] in ['Default', 'Charged Off']:\n",
    "                # For defaulted loans, calculate progression of overdue days\n",
    "                days_since_origination = (current_date - pd.to_datetime(loan['origination_date'])).days\n",
    "                days_to_end = (end_date - pd.to_datetime(loan['origination_date'])).days\n",
    "                overdue_days[idx] = min(180, max(0, loan['days_past_due'] - (days_to_end - days_since_origination)))\n",
    "            elif loan['loan_status'] == 'Current' and loan['days_past_due'] > 0:\n",
    "                # Show overdue only if we're in the last 30 days before end_date\n",
    "                if (end_date - current_date).days <= 30:\n",
    "                    overdue_days[idx] = loan['days_past_due']\n",
    "                else:\n",
    "                    overdue_days[idx] = 0\n",
    "            else:\n",
    "                overdue_days[idx] = 0\n",
    "\n",
    "        # Determine payment status\n",
    "        payment_status = pd.cut(\n",
    "            overdue_days,\n",
    "            bins=[-np.inf, 0, 30, 60, 90, np.inf],\n",
    "            labels=['Current', '0-30 DPD', '30-60 DPD', '60-90 DPD', 'Default'],\n",
    "            right=True\n",
    "        )\n",
    "\n",
    "        # Create records for this date\n",
    "        date_records = pd.DataFrame({\n",
    "            'loanid': active_loans['loanid'].values,\n",
    "            'appid': active_loans['appid'].values,\n",
    "            'personid': active_loans['personid'].values,  # Added personid\n",
    "            'observation_date': current_date.date(),\n",
    "            'days_on_book': days_on_book.values,\n",
    "            'months_on_book': (days_on_book.values // 30),\n",
    "            'current_balance': current_balances.round(2),\n",
    "            'overdue_days': overdue_days,\n",
    "            'payment_status': payment_status,\n",
    "            'ever_delinquent': (overdue_days > 0) | active_loans['loan_status'].isin(['Default', 'Charged Off']),\n",
    "            'loan_status': active_loans['loan_status'].values,  # Current loan status\n",
    "            'created_at': current_date + pd.Timedelta(hours=1),\n",
    "            'updated_at': current_date + pd.Timedelta(hours=1)\n",
    "        })\n",
    "\n",
    "        all_records.append(date_records)\n",
    "\n",
    "    # Combine all records\n",
    "    if all_records:\n",
    "        result_df = pd.concat(all_records, ignore_index=True)\n",
    "        result_df['vwlob_id'] = np.arange(1, len(result_df) + 1)\n",
    "\n",
    "        # Return with proper column order\n",
    "        columns_order = [\n",
    "            'vwlob_id', 'loanid', 'appid', 'personid', 'observation_date',\n",
    "            'days_on_book', 'months_on_book', 'current_balance', 'overdue_days',\n",
    "            'payment_status', 'ever_delinquent', 'max_delinquency', 'loan_status',\n",
    "            'created_at', 'updated_at'\n",
    "        ]\n",
    "\n",
    "        return result_df[columns_order]\n",
    "    else:\n",
    "        return pd.DataFrame(columns=[\n",
    "            'vwlob_id', 'loanid', 'appid', 'personid', 'observation_date',\n",
    "            'days_on_book', 'months_on_book', 'current_balance', 'overdue_days',\n",
    "            'payment_status', 'ever_delinquent', 'max_delinquency', 'loan_status',\n",
    "            'created_at', 'updated_at'\n",
    "        ])\n",
    "\n",
    "def generate_wof(n, loans_df):\n",
    "    \"\"\"Generate write-off records for defaulted loans\"\"\"\n",
    "    wof_records = []\n",
    "\n",
    "    # Check if loans_df is empty or if loan_status column exists\n",
    "    if len(loans_df) == 0:\n",
    "        print(\"Warning: No loans data available for write-offs\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Check what columns are available\n",
    "    # print(f\"Available columns in loans_df: {loans_df.columns.tolist()}\")\n",
    "\n",
    "    # Check if loan_status column exists, if not try alternative column names\n",
    "    status_column = None\n",
    "    if 'loan_status' in loans_df.columns:\n",
    "        status_column = 'loan_status'\n",
    "    elif 'status' in loans_df.columns:\n",
    "        status_column = 'status'\n",
    "    elif 'loanStatus' in loans_df.columns:\n",
    "        status_column = 'loanStatus'\n",
    "\n",
    "    if status_column is None:\n",
    "        print(\"Warning: No status column found in loans dataframe\")\n",
    "        # Create some synthetic write-offs based on loan age or other criteria\n",
    "        # For now, just take a random sample of loans\n",
    "        sample_size = min(n, len(loans_df))\n",
    "        sample_loans = loans_df.sample(sample_size)\n",
    "    else:\n",
    "        # Only process charged off loans\n",
    "        charged_off_loans = loans_df[loans_df[status_column] == 'Charged Off']\n",
    "\n",
    "        if len(charged_off_loans) == 0:\n",
    "            print(\"Warning: No charged off loans found, creating synthetic write-offs\")\n",
    "            # Take a random sample of loans to create synthetic write-offs\n",
    "            sample_size = min(n, max(1, int(len(loans_df) * 0.02)))  # 2% of loans\n",
    "            sample_loans = loans_df.sample(sample_size)\n",
    "        else:\n",
    "            sample_loans = charged_off_loans\n",
    "\n",
    "    # Generate write-off records\n",
    "    for idx, loan in sample_loans.iterrows():\n",
    "        if len(wof_records) >= n:\n",
    "            break\n",
    "\n",
    "        # Get origination date\n",
    "        if 'origination_date' in loan:\n",
    "            origination_date = loan['origination_date']\n",
    "        elif 'originationDate' in loan:\n",
    "            origination_date = loan['originationDate']\n",
    "        elif 'start_date' in loan:\n",
    "            origination_date = loan['start_date']\n",
    "        else:\n",
    "            # Use current date minus some random days if no origination date found\n",
    "            origination_date = datetime.now() - timedelta(days=np.random.randint(180, 720))\n",
    "\n",
    "        # Ensure origination_date is datetime\n",
    "        if not isinstance(origination_date, datetime):\n",
    "            try:\n",
    "                origination_date = pd.to_datetime(origination_date)\n",
    "            except:\n",
    "                origination_date = datetime.now() - timedelta(days=np.random.randint(180, 720))\n",
    "\n",
    "        # Write-off typically happens after 180 days of delinquency\n",
    "        wof_date = origination_date + timedelta(days=180 + np.random.randint(0, 30))\n",
    "\n",
    "        # Get loan amount\n",
    "        if 'current_balance' in loan and pd.notna(loan['current_balance']):\n",
    "            wof_amount = loan['current_balance']\n",
    "        elif 'original_amount' in loan and pd.notna(loan['original_amount']):\n",
    "            wof_amount = loan['original_amount'] * np.random.uniform(0.3, 0.8)\n",
    "        elif 'amount' in loan and pd.notna(loan['amount']):\n",
    "            wof_amount = loan['amount'] * np.random.uniform(0.3, 0.8)\n",
    "        else:\n",
    "            wof_amount = np.random.uniform(5000, 50000)\n",
    "\n",
    "        # Recovery information\n",
    "        recovery_rate = np.random.beta(2, 8)  # Most recoveries are low\n",
    "        expected_recovery = wof_amount * recovery_rate\n",
    "        actual_recovery = expected_recovery * np.random.uniform(0, 1.2)  # Some variation\n",
    "\n",
    "        # Get personid\n",
    "        if 'personid' in loan:\n",
    "            personid = loan['personid']\n",
    "        elif 'person_id' in loan:\n",
    "            personid = loan['person_id']\n",
    "        elif 'customer_id' in loan:\n",
    "            personid = loan['customer_id']\n",
    "        else:\n",
    "            personid = np.random.randint(1, 10000)\n",
    "\n",
    "        # Get loanid\n",
    "        if 'loanid' in loan:\n",
    "            loanid = loan['loanid']\n",
    "        elif 'loan_id' in loan:\n",
    "            loanid = loan['loan_id']\n",
    "        elif 'id' in loan:\n",
    "            loanid = loan['id']\n",
    "        else:\n",
    "            loanid = idx\n",
    "\n",
    "        wof_records.append({\n",
    "            'wof_id': len(wof_records) + 1,\n",
    "            'loanid': loanid,\n",
    "            'personid': personid,\n",
    "            'wof_date': wof_date.date() if hasattr(wof_date, 'date') else wof_date,\n",
    "            'wof_amount': round(wof_amount, 2),\n",
    "            'wof_reason': np.random.choice(['Non-Payment', 'Bankruptcy', 'Deceased', 'Fraud', 'Other'],\n",
    "                                         p=[0.7, 0.15, 0.05, 0.05, 0.05]),\n",
    "            'expected_recovery': round(expected_recovery, 2),\n",
    "            'actual_recovery': round(actual_recovery, 2),\n",
    "            'recovery_status': 'Completed' if actual_recovery > 0 else 'In Progress',\n",
    "            'collection_agency': np.random.choice(['Internal', 'Agency A', 'Agency B', 'Agency C'],\n",
    "                                                p=[0.3, 0.3, 0.2, 0.2]),\n",
    "            'created_at': wof_date,\n",
    "            'updated_at': wof_date + timedelta(days=np.random.randint(1, 30))\n",
    "        })\n",
    "\n",
    "    if len(wof_records) == 0:\n",
    "        # Return empty dataframe with proper structure\n",
    "        return pd.DataFrame(columns=['wof_id', 'loanid', 'personid', 'wof_date', 'wof_amount',\n",
    "                                    'wof_reason', 'expected_recovery', 'actual_recovery',\n",
    "                                    'recovery_status', 'collection_agency', 'created_at', 'updated_at'])\n",
    "\n",
    "    return pd.DataFrame(wof_records)\n",
    "\n",
    "def generate_related_persons(n, persons_df):\n",
    "    \"\"\"Generate relationships between persons\"\"\"\n",
    "    related_records = []\n",
    "    relationship_types = ['Spouse', 'Parent', 'Child', 'Sibling', 'Business Partner', 'Co-applicant']\n",
    "\n",
    "    # Identify potential relationships\n",
    "    for _ in range(n):\n",
    "        person1 = persons_df.sample(1).iloc[0]\n",
    "\n",
    "        # Find a suitable related person\n",
    "        if person1['marital_status'] == 'Married' and np.random.random() < 0.7:\n",
    "            # Find a spouse\n",
    "            potential_spouses = persons_df[\n",
    "                (persons_df['personid'] != person1['personid']) &\n",
    "                (persons_df['marital_status'] == 'Married') &\n",
    "                (abs(persons_df['age'] - person1['age']) < 15)\n",
    "            ]\n",
    "            if len(potential_spouses) > 0:\n",
    "                person2 = potential_spouses.sample(1).iloc[0]\n",
    "                relationship_type = 'Spouse'\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            # Random relationship\n",
    "            person2 = persons_df[persons_df['personid'] != person1['personid']].sample(1).iloc[0]\n",
    "            relationship_type = np.random.choice(relationship_types[1:])  # Exclude spouse\n",
    "\n",
    "        related_records.append({\n",
    "            'relationship_id': len(related_records) + 1,\n",
    "            'personid': person1['personid'],\n",
    "            'related_personid': person2['personid'],\n",
    "            'relationship_type': relationship_type,\n",
    "            'start_date': fake.date_between(start_date='-10y', end_date='-1y'),\n",
    "            'end_date': None if np.random.random() < 0.8 else fake.date_between(start_date='-1y', end_date='today'),\n",
    "            'is_active': np.random.random() < 0.9,\n",
    "            'created_at': fake.date_time_between(start_date='-2y', end_date='now'),\n",
    "            'updated_at': fake.date_time_between(start_date='-1y', end_date='now')\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(related_records)\n",
    "\n",
    "def generate_guarantors(n, loans_df, persons_df):\n",
    "    \"\"\"Generate guarantor records for some loans\"\"\"\n",
    "    guarantor_records = []\n",
    "\n",
    "    # Check if loans_df is empty\n",
    "    if len(loans_df) == 0:\n",
    "        print(\"Warning: No loans data available for guarantors\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Check available columns\n",
    "    # print(f\"Available columns in loans_df: {loans_df.columns.tolist()}\")\n",
    "\n",
    "    # Find amount column\n",
    "    amount_column = None\n",
    "    for col in ['original_amount', 'loan_amount', 'amount', 'loan_size', 'principal']:\n",
    "        if col in loans_df.columns:\n",
    "            amount_column = col\n",
    "            break\n",
    "\n",
    "    # Find product type column\n",
    "    product_column = None\n",
    "    for col in ['product_type', 'loan_type', 'product', 'type']:\n",
    "        if col in loans_df.columns:\n",
    "            product_column = col\n",
    "            break\n",
    "\n",
    "    # Select loans that might need guarantors\n",
    "    if amount_column and product_column:\n",
    "        # Select loans based on amount and product type\n",
    "        eligible_loans = loans_df[\n",
    "            (loans_df[amount_column] > 50000) |\n",
    "            (loans_df[product_column].isin(['Business Loan', 'Mortgage']))\n",
    "        ]\n",
    "    elif amount_column:\n",
    "        # Select loans based on amount only\n",
    "        eligible_loans = loans_df[loans_df[amount_column] > 50000]\n",
    "    else:\n",
    "        # If no criteria columns found, take a random sample\n",
    "        sample_size = min(n * 5, len(loans_df))  # Sample more to get enough guarantors\n",
    "        eligible_loans = loans_df.sample(sample_size)\n",
    "\n",
    "    # Generate guarantors for eligible loans\n",
    "    for idx, loan in eligible_loans.iterrows():\n",
    "        if np.random.random() < 0.2:  # 20% of eligible loans have guarantors\n",
    "            # Find potential guarantors (different person, good credit)\n",
    "            if 'personid' in loan:\n",
    "                borrower_id = loan['personid']\n",
    "            elif 'person_id' in loan:\n",
    "                borrower_id = loan['person_id']\n",
    "            elif 'customer_id' in loan:\n",
    "                borrower_id = loan['customer_id']\n",
    "            else:\n",
    "                borrower_id = np.random.randint(1, len(persons_df))\n",
    "\n",
    "            # Find suitable guarantors\n",
    "            potential_guarantors = persons_df[\n",
    "                (persons_df['personid'] != borrower_id) &\n",
    "                (persons_df['credit_score'] > 700)\n",
    "            ]\n",
    "\n",
    "            # If no suitable guarantors based on credit score, relax criteria\n",
    "            if len(potential_guarantors) == 0:\n",
    "                potential_guarantors = persons_df[\n",
    "                    (persons_df['personid'] != borrower_id) &\n",
    "                    (persons_df['credit_score'] > 650)\n",
    "                ]\n",
    "\n",
    "            # If still no suitable guarantors, take any other person\n",
    "            if len(potential_guarantors) == 0:\n",
    "                potential_guarantors = persons_df[persons_df['personid'] != borrower_id]\n",
    "\n",
    "            if len(potential_guarantors) > 0:\n",
    "                guarantor = potential_guarantors.sample(1).iloc[0]\n",
    "\n",
    "                # Get loan amount\n",
    "                if amount_column and amount_column in loan:\n",
    "                    guarantee_amount = loan[amount_column]\n",
    "                else:\n",
    "                    guarantee_amount = np.random.uniform(10000, 100000)\n",
    "\n",
    "                # Get loan id\n",
    "                if 'loanid' in loan:\n",
    "                    loan_id = loan['loanid']\n",
    "                elif 'loan_id' in loan:\n",
    "                    loan_id = loan['loan_id']\n",
    "                elif 'id' in loan:\n",
    "                    loan_id = loan['id']\n",
    "                else:\n",
    "                    loan_id = idx\n",
    "\n",
    "                # Get dates\n",
    "                if 'origination_date' in loan:\n",
    "                    start_date = loan['origination_date']\n",
    "                elif 'start_date' in loan:\n",
    "                    start_date = loan['start_date']\n",
    "                elif 'funding_date' in loan:\n",
    "                    start_date = loan['funding_date']\n",
    "                else:\n",
    "                    start_date = datetime.now() - timedelta(days=np.random.randint(30, 365))\n",
    "\n",
    "                if 'maturity_date' in loan:\n",
    "                    end_date = loan['maturity_date']\n",
    "                elif 'end_date' in loan:\n",
    "                    end_date = loan['end_date']\n",
    "                else:\n",
    "                    end_date = start_date + timedelta(days=365 * np.random.randint(1, 5))\n",
    "\n",
    "                # Ensure dates are datetime objects\n",
    "                if not isinstance(start_date, datetime):\n",
    "                    try:\n",
    "                        start_date = pd.to_datetime(start_date)\n",
    "                    except:\n",
    "                        start_date = datetime.now() - timedelta(days=np.random.randint(30, 365))\n",
    "\n",
    "                if not isinstance(end_date, datetime):\n",
    "                    try:\n",
    "                        end_date = pd.to_datetime(end_date)\n",
    "                    except:\n",
    "                        end_date = start_date + timedelta(days=365 * np.random.randint(1, 5))\n",
    "\n",
    "                guarantor_records.append({\n",
    "                    'guarantor_id': len(guarantor_records) + 1,\n",
    "                    'loanid': loan_id,\n",
    "                    'guarantor_personid': guarantor['personid'],\n",
    "                    'borrower_personid': borrower_id,\n",
    "                    'guarantee_amount': round(guarantee_amount, 2),\n",
    "                    'guarantee_type': np.random.choice(['Full', 'Partial', 'Limited'],\n",
    "                                                     p=[0.6, 0.3, 0.1]),\n",
    "                    'guarantee_start_date': start_date,\n",
    "                    'guarantee_end_date': end_date,\n",
    "                    'guarantee_status': np.random.choice(['Active', 'Released', 'Called'],\n",
    "                                                       p=[0.8, 0.15, 0.05]),\n",
    "                    'created_at': start_date,\n",
    "                    'updated_at': datetime.now()\n",
    "                })\n",
    "\n",
    "                if len(guarantor_records) >= n:\n",
    "                    break\n",
    "\n",
    "    # If we don't have enough guarantors, create some synthetic ones\n",
    "    while len(guarantor_records) < n:\n",
    "        # Select random loan and person\n",
    "        if len(loans_df) > 0:\n",
    "            loan = loans_df.sample(1).iloc[0]\n",
    "            loan_id = loan.get('loanid', loan.get('loan_id', loan.get('id', len(guarantor_records))))\n",
    "        else:\n",
    "            loan_id = len(guarantor_records) + 1\n",
    "\n",
    "        # Select two different persons\n",
    "        if len(persons_df) >= 2:\n",
    "            two_persons = persons_df.sample(2)\n",
    "            borrower = two_persons.iloc[0]\n",
    "            guarantor = two_persons.iloc[1]\n",
    "        else:\n",
    "            # Create synthetic IDs if not enough persons\n",
    "            borrower_id = 1\n",
    "            guarantor_id = 2\n",
    "\n",
    "        guarantor_records.append({\n",
    "            'guarantor_id': len(guarantor_records) + 1,\n",
    "            'loanid': loan_id,\n",
    "            'guarantor_personid': guarantor['personid'] if 'guarantor' in locals() else guarantor_id,\n",
    "            'borrower_personid': borrower['personid'] if 'borrower' in locals() else borrower_id,\n",
    "            'guarantee_amount': round(np.random.uniform(10000, 100000), 2),\n",
    "            'guarantee_type': np.random.choice(['Full', 'Partial', 'Limited'],\n",
    "                                             p=[0.6, 0.3, 0.1]),\n",
    "            'guarantee_start_date': datetime.now() - timedelta(days=np.random.randint(30, 365)),\n",
    "            'guarantee_end_date': datetime.now() + timedelta(days=np.random.randint(30, 365*3)),\n",
    "            'guarantee_status': np.random.choice(['Active', 'Released', 'Called'],\n",
    "                                               p=[0.8, 0.15, 0.05]),\n",
    "            'created_at': datetime.now() - timedelta(days=np.random.randint(1, 30)),\n",
    "            'updated_at': datetime.now()\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(guarantor_records[:n])\n",
    "\n",
    "def generate_collateral(n, loans_df):\n",
    "    \"\"\"Generate collateral records for secured loans\"\"\"\n",
    "    collateral_records = []\n",
    "\n",
    "    # Check if loans_df is empty\n",
    "    if len(loans_df) == 0:\n",
    "        print(\"Warning: No loans data available for collateral\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Check available columns\n",
    "    # print(f\"Available columns in loans_df: {loans_df.columns.tolist()}\")\n",
    "\n",
    "    # Find product type column\n",
    "    product_column = None\n",
    "    for col in ['product_type', 'loan_type', 'product', 'type', 'loan_product']:\n",
    "        if col in loans_df.columns:\n",
    "            product_column = col\n",
    "            break\n",
    "\n",
    "    # Find amount column - DEFINE HERE for the whole function\n",
    "    amount_column = None\n",
    "    for col in ['original_amount', 'loan_amount', 'amount', 'loan_size', 'principal']:\n",
    "        if col in loans_df.columns:\n",
    "            amount_column = col\n",
    "            break\n",
    "\n",
    "    # Select loans that should have collateral\n",
    "    if product_column:\n",
    "        secured_loans = loans_df[loans_df[product_column].isin(['Mortgage', 'Auto Loan', 'Business Loan'])]\n",
    "    else:\n",
    "        # If no product column found, take a sample based on loan amount\n",
    "        if amount_column:\n",
    "            # Assume larger loans are more likely to be secured\n",
    "            secured_loans = loans_df[loans_df[amount_column] > 50000]\n",
    "        else:\n",
    "            # Take a random sample if no criteria columns found\n",
    "            sample_size = min(n * 2, len(loans_df))  # Sample more to get enough collateral\n",
    "            secured_loans = loans_df.sample(sample_size)\n",
    "\n",
    "    # Generate collateral records\n",
    "    for idx, loan in secured_loans.iterrows():\n",
    "        if len(collateral_records) >= n:\n",
    "            break\n",
    "\n",
    "        # Determine collateral type based on product type or loan amount\n",
    "        if product_column and product_column in loan:\n",
    "            product_type = loan[product_column]\n",
    "            if product_type == 'Mortgage':\n",
    "                collateral_type = 'Real Estate'\n",
    "                description = f\"{np.random.choice(['Single Family', 'Condo', 'Townhouse', 'Multi-family'])} Property\"\n",
    "                value_multiplier = np.random.uniform(1.1, 1.5)\n",
    "            elif product_type == 'Auto Loan':\n",
    "                collateral_type = 'Vehicle'\n",
    "                description = f\"{np.random.choice(['New', 'Used'])} Vehicle\"\n",
    "                value_multiplier = np.random.uniform(1.05, 1.3)\n",
    "            elif product_type == 'Business Loan':\n",
    "                collateral_type = np.random.choice(['Equipment', 'Inventory', 'Accounts Receivable', 'Real Estate'])\n",
    "                description = f\"Business {collateral_type}\"\n",
    "                value_multiplier = np.random.uniform(1.2, 2.0)\n",
    "            else:\n",
    "                collateral_type = np.random.choice(['Real Estate', 'Vehicle', 'Equipment', 'Other'])\n",
    "                description = f\"{collateral_type} Asset\"\n",
    "                value_multiplier = np.random.uniform(1.1, 1.5)\n",
    "        else:\n",
    "            # Determine collateral type based on loan amount\n",
    "            if amount_column and loan[amount_column] > 100000:\n",
    "                collateral_type = 'Real Estate'\n",
    "                description = \"Property\"\n",
    "                value_multiplier = np.random.uniform(1.2, 1.8)\n",
    "            elif amount_column and loan[amount_column] > 20000:\n",
    "                collateral_type = 'Vehicle'\n",
    "                description = \"Vehicle\"\n",
    "                value_multiplier = np.random.uniform(1.1, 1.4)\n",
    "            else:\n",
    "                collateral_type = np.random.choice(['Equipment', 'Inventory', 'Other'])\n",
    "                description = f\"{collateral_type} Asset\"\n",
    "                value_multiplier = np.random.uniform(1.1, 1.5)\n",
    "\n",
    "        # Get loan amount\n",
    "        loan_amount = 0\n",
    "        if amount_column and amount_column in loan:\n",
    "            loan_amount = loan[amount_column]\n",
    "        else:\n",
    "            loan_amount = np.random.uniform(10000, 500000)\n",
    "\n",
    "        collateral_value = loan_amount * value_multiplier\n",
    "\n",
    "        # Get loan id\n",
    "        if 'loanid' in loan:\n",
    "            loan_id = loan['loanid']\n",
    "        elif 'loan_id' in loan:\n",
    "            loan_id = loan['loan_id']\n",
    "        elif 'id' in loan:\n",
    "            loan_id = loan['id']\n",
    "        else:\n",
    "            loan_id = idx\n",
    "\n",
    "        # Get dates\n",
    "        if 'origination_date' in loan:\n",
    "            valuation_date = loan['origination_date'] - timedelta(days=np.random.randint(1, 30))\n",
    "        elif 'start_date' in loan:\n",
    "            valuation_date = loan['start_date'] - timedelta(days=np.random.randint(1, 30))\n",
    "        elif 'funding_date' in loan:\n",
    "            valuation_date = loan['funding_date'] - timedelta(days=np.random.randint(1, 30))\n",
    "        else:\n",
    "            valuation_date = datetime.now() - timedelta(days=np.random.randint(60, 365))\n",
    "\n",
    "        # Ensure valuation_date is datetime\n",
    "        if not isinstance(valuation_date, datetime):\n",
    "            try:\n",
    "                valuation_date = pd.to_datetime(valuation_date)\n",
    "            except:\n",
    "                valuation_date = datetime.now() - timedelta(days=np.random.randint(60, 365))\n",
    "\n",
    "        collateral_records.append({\n",
    "            'collateral_id': len(collateral_records) + 1,\n",
    "            'loanid': loan_id,\n",
    "            'collateral_type': collateral_type,\n",
    "            'description': description,\n",
    "            'original_value': round(collateral_value, 2),\n",
    "            'current_value': round(collateral_value * np.random.uniform(0.9, 1.1), 2),\n",
    "            'valuation_date': valuation_date.date() if hasattr(valuation_date, 'date') else valuation_date,\n",
    "            'valuation_method': np.random.choice(['Appraisal', 'Market Value', 'Book Value', 'Third Party']),\n",
    "            'ltv_ratio': round(loan_amount / collateral_value, 3),\n",
    "            'insurance_required': True,\n",
    "            'insurance_provider': np.random.choice(['Provider A', 'Provider B', 'Provider C', 'Other']),\n",
    "            'insurance_policy_number': fake.bothify(text='POL-########'),\n",
    "            'lien_position': np.random.choice(['First', 'Second'], p=[0.9, 0.1]),\n",
    "            'status': np.random.choice(['Active', 'Released'], p=[0.9, 0.1]),\n",
    "            'created_at': valuation_date,\n",
    "            'updated_at': datetime.now()\n",
    "        })\n",
    "\n",
    "    # If we don't have enough collateral records, create synthetic ones\n",
    "    while len(collateral_records) < n:\n",
    "        loan_id = len(collateral_records) + 1\n",
    "        loan_amount = np.random.uniform(10000, 500000)\n",
    "        collateral_value = loan_amount * np.random.uniform(1.1, 2.0)\n",
    "        valuation_date = datetime.now() - timedelta(days=np.random.randint(30, 365))\n",
    "\n",
    "        collateral_records.append({\n",
    "            'collateral_id': len(collateral_records) + 1,\n",
    "            'loanid': loan_id,\n",
    "            'collateral_type': np.random.choice(['Real Estate', 'Vehicle', 'Equipment', 'Inventory', 'Other']),\n",
    "            'description': f\"Asset #{len(collateral_records) + 1}\",\n",
    "            'original_value': round(collateral_value, 2),\n",
    "            'current_value': round(collateral_value * np.random.uniform(0.9, 1.1), 2),\n",
    "            'valuation_date': valuation_date.date(),\n",
    "            'valuation_method': np.random.choice(['Appraisal', 'Market Value', 'Book Value', 'Third Party']),\n",
    "            'ltv_ratio': round(loan_amount / collateral_value, 3),\n",
    "            'insurance_required': True,\n",
    "            'insurance_provider': np.random.choice(['Provider A', 'Provider B', 'Provider C', 'Other']),\n",
    "            'insurance_policy_number': fake.bothify(text='POL-########'),\n",
    "            'lien_position': np.random.choice(['First', 'Second'], p=[0.9, 0.1]),\n",
    "            'status': np.random.choice(['Active', 'Released'], p=[0.9, 0.1]),\n",
    "            'created_at': valuation_date,\n",
    "            'updated_at': datetime.now()\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(collateral_records[:n])\n",
    "\n",
    "def generate_synthetic_database():\n",
    "    \"\"\"Main function to generate all synthetic data\"\"\"\n",
    "    print(\"Starting synthetic data generation...\")\n",
    "    print(f\"Target database size: {TARGET_FINAL_SIZE_GB}GB\")\n",
    "    print(f\"Scaling factor: {scaling_factor:.2f}\")\n",
    "\n",
    "    # Create output directory\n",
    "    os.makedirs(\"./synthetic_data\", exist_ok=True)\n",
    "\n",
    "    synthetic_data = {}\n",
    "\n",
    "    def timed_step(step_name, func, *args):\n",
    "        start = time.time()\n",
    "        result = func(*args)\n",
    "        duration = time.time() - start\n",
    "        print(f\"{step_name} completed in {duration:.2f} seconds.\")\n",
    "        return result\n",
    "\n",
    "    # Generate data in order of dependencies\n",
    "    synthetic_data['persons'] = timed_step(\"1. Generating persons\", generate_persons, TARGET_ROW_COUNTS['persons'])\n",
    "    synthetic_data['person_employment'] = timed_step(\"2. Generating person employment\", generate_person_employment, TARGET_ROW_COUNTS['person_employment'], synthetic_data['persons'])\n",
    "    synthetic_data['applications'] = timed_step(\"3. Generating applications\", generate_applications, TARGET_ROW_COUNTS['applications'], synthetic_data['persons'], synthetic_data['person_employment'])\n",
    "    synthetic_data['application_financial'] = timed_step(\"4. Generating application financial data\", generate_application_financial, TARGET_ROW_COUNTS['application_financial'], synthetic_data['applications'], synthetic_data['persons'], synthetic_data['person_employment'])\n",
    "    synthetic_data['credit_scoring'] = timed_step(\"5. Generating credit scoring\", generate_credit_scoring, TARGET_ROW_COUNTS['credit_scoring'], synthetic_data['applications'], synthetic_data['persons'], synthetic_data['application_financial'])\n",
    "    synthetic_data['loans'] = timed_step(\"6. Generating loans\", generate_loans, TARGET_ROW_COUNTS['loans'], synthetic_data['applications'])\n",
    "    synthetic_data['loan_payments'] = timed_step(\"7. Generating loan payments\", generate_loan_payments, TARGET_ROW_COUNTS['loan_payments'], synthetic_data['loans'])\n",
    "    synthetic_data['transactions'] = timed_step(\"8. Generating transactions\", generate_transactions, TARGET_ROW_COUNTS['transactions'], synthetic_data['persons'])\n",
    "    synthetic_data['transactions_p2p'] = timed_step(\"9. Generating P2P transactions\", generate_transactions_p2p, TARGET_ROW_COUNTS['transactions_p2p'], synthetic_data['persons'])\n",
    "    synthetic_data['vwlob'] = timed_step(\"10. Generating loan observations (vwlob)\", generate_vwlob, synthetic_data['loans'][\"origination_date\"].max(), synthetic_data['loans'])\n",
    "    synthetic_data['wof'] = timed_step(\"11. Generating write-offs\", generate_wof, TARGET_ROW_COUNTS['wof'], synthetic_data['loans'])\n",
    "    synthetic_data['related_persons'] = timed_step(\"12. Generating related persons\", generate_related_persons, TARGET_ROW_COUNTS['related_persons'], synthetic_data['persons'])\n",
    "    synthetic_data['guarantors'] = timed_step(\"13. Generating guarantors\", generate_guarantors, TARGET_ROW_COUNTS['guarantors'], synthetic_data['loans'], synthetic_data['persons'])\n",
    "    synthetic_data['collateral'] = timed_step(\"14. Generating collateral\", generate_collateral, TARGET_ROW_COUNTS['collateral'], synthetic_data['loans'])\n",
    "\n",
    "    # Calculate actual size\n",
    "    print(\"\\n=== Table Statistics ===\")\n",
    "    total_size_bytes = 0\n",
    "    for name, df in synthetic_data.items():\n",
    "        size_bytes = df.memory_usage(deep=True).sum()\n",
    "        size_mb = size_bytes / (1024 ** 2)\n",
    "        total_size_bytes += size_bytes\n",
    "        print(f\"{name:<25}: {len(df):>10,} rows, {size_mb:>8.1f} MB\")\n",
    "\n",
    "    total_size_gb = total_size_bytes / (1024 ** 3)\n",
    "    print(f\"\\n{'TOTAL':<25}: {total_size_gb:>8.2f} GB\")\n",
    "\n",
    "    # Save to pickle\n",
    "    # output_file = './synthetic_data/synthetic_database.pkl'\n",
    "    # print(f\"\\nSaving to {output_file}...\")\n",
    "    # with open(output_file, 'wb') as f:\n",
    "    #     pickle.dump(synthetic_data, f)\n",
    "\n",
    "    print(\"\\nData generation complete!\")\n",
    "    return synthetic_data\n",
    "\n"
   ],
   "id": "c1fbf7017fdc90dc",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T10:53:48.622177Z",
     "start_time": "2025-05-03T10:53:16.102469Z"
    }
   },
   "cell_type": "code",
   "source": "synthetic_data = generate_synthetic_database()",
   "id": "4c1716363b406758",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting synthetic data generation...\n",
      "Target database size: 0.1GB\n",
      "Scaling factor: 0.01\n",
      "1. Generating persons completed in 0.39 seconds.\n",
      "2. Generating person employment completed in 0.56 seconds.\n",
      "3. Generating applications completed in 0.14 seconds.\n",
      "4. Generating application financial data completed in 0.30 seconds.\n",
      "5. Generating credit scoring completed in 0.02 seconds.\n",
      "6. Generating loans completed in 0.01 seconds.\n",
      "7. Generating loan payments completed in 0.92 seconds.\n",
      "8. Generating transactions completed in 5.70 seconds.\n",
      "9. Generating P2P transactions completed in 0.36 seconds.\n",
      "10. Generating loan observations (vwlob) completed in 23.55 seconds.\n",
      "11. Generating write-offs completed in 0.00 seconds.\n",
      "12. Generating related persons completed in 0.15 seconds.\n",
      "13. Generating guarantors completed in 0.08 seconds.\n",
      "14. Generating collateral completed in 0.03 seconds.\n",
      "\n",
      "=== Table Statistics ===\n",
      "persons                  :      1,212 rows,      1.3 MB\n",
      "person_employment        :      1,769 rows,      1.3 MB\n",
      "applications             :      3,030 rows,      2.1 MB\n",
      "application_financial    :      3,030 rows,      1.0 MB\n",
      "credit_scoring           :      3,030 rows,      1.9 MB\n",
      "loans                    :      1,675 rows,      0.5 MB\n",
      "loan_payments            :     14,392 rows,      3.2 MB\n",
      "transactions             :    121,203 rows,     99.4 MB\n",
      "transactions_p2p         :     24,240 rows,      9.5 MB\n",
      "vwlob                    :    480,301 rows,     88.9 MB\n",
      "wof                      :         24 rows,      0.0 MB\n",
      "related_persons          :        121 rows,      0.0 MB\n",
      "guarantors               :         96 rows,      0.0 MB\n",
      "collateral               :        181 rows,      0.1 MB\n",
      "\n",
      "TOTAL                    :     0.20 GB\n",
      "\n",
      "Data generation complete!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T11:30:46.315472Z",
     "start_time": "2025-05-03T11:30:46.301525Z"
    }
   },
   "cell_type": "code",
   "source": "synthetic_data[\"vwlob\"]",
   "id": "7f632b7183b6f7c4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        vwlob_id  loanid  appid  personid observation_date  days_on_book  \\\n",
       "0              1    1277   2324       893       2023-05-07             0   \n",
       "1              2    1277   2324       893       2023-05-08             1   \n",
       "2              3    1277   2324       893       2023-05-09             2   \n",
       "3              4    1277   2324       893       2023-05-10             3   \n",
       "4              5    1277   2324       893       2023-05-11             4   \n",
       "...          ...     ...    ...       ...              ...           ...   \n",
       "480296    480297    1666   3017      1206       2025-05-23           527   \n",
       "480297    480298    1667   3018       595       2025-05-23           392   \n",
       "480298    480299    1670   3022       530       2025-05-23           279   \n",
       "480299    480300    1674   3028       295       2025-05-23            15   \n",
       "480300    480301    1675   3030      1156       2025-05-23           468   \n",
       "\n",
       "        months_on_book  current_balance  overdue_days payment_status  \\\n",
       "0                    0         26395.68             0        Current   \n",
       "1                    0         26377.48             0        Current   \n",
       "2                    0         26359.27             0        Current   \n",
       "3                    0         26341.07             0        Current   \n",
       "4                    0         26322.86             0        Current   \n",
       "...                ...              ...           ...            ...   \n",
       "480296              17         19477.40             0        Current   \n",
       "480297              13         31716.93             0        Current   \n",
       "480298               9         17835.63             0        Current   \n",
       "480299               0         33900.16             0        Current   \n",
       "480300              15         14344.35             0        Current   \n",
       "\n",
       "        ever_delinquent  max_delinquency loan_status          created_at  \\\n",
       "0                 False                0     Current 2023-05-07 05:37:12   \n",
       "1                 False                0     Current 2023-05-08 05:37:12   \n",
       "2                 False                0     Current 2023-05-09 05:37:12   \n",
       "3                 False                0     Current 2023-05-10 05:37:12   \n",
       "4                 False                0     Current 2023-05-11 05:37:12   \n",
       "...                 ...              ...         ...                 ...   \n",
       "480296            False                0     Current 2025-05-23 05:37:12   \n",
       "480297            False                0     Current 2025-05-23 05:37:12   \n",
       "480298            False                0     Current 2025-05-23 05:37:12   \n",
       "480299            False                0     Pending 2025-05-23 05:37:12   \n",
       "480300            False                0     Current 2025-05-23 05:37:12   \n",
       "\n",
       "                updated_at  \n",
       "0      2023-05-07 05:37:12  \n",
       "1      2023-05-08 05:37:12  \n",
       "2      2023-05-09 05:37:12  \n",
       "3      2023-05-10 05:37:12  \n",
       "4      2023-05-11 05:37:12  \n",
       "...                    ...  \n",
       "480296 2025-05-23 05:37:12  \n",
       "480297 2025-05-23 05:37:12  \n",
       "480298 2025-05-23 05:37:12  \n",
       "480299 2025-05-23 05:37:12  \n",
       "480300 2025-05-23 05:37:12  \n",
       "\n",
       "[480301 rows x 15 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vwlob_id</th>\n",
       "      <th>loanid</th>\n",
       "      <th>appid</th>\n",
       "      <th>personid</th>\n",
       "      <th>observation_date</th>\n",
       "      <th>days_on_book</th>\n",
       "      <th>months_on_book</th>\n",
       "      <th>current_balance</th>\n",
       "      <th>overdue_days</th>\n",
       "      <th>payment_status</th>\n",
       "      <th>ever_delinquent</th>\n",
       "      <th>max_delinquency</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1277</td>\n",
       "      <td>2324</td>\n",
       "      <td>893</td>\n",
       "      <td>2023-05-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26395.68</td>\n",
       "      <td>0</td>\n",
       "      <td>Current</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Current</td>\n",
       "      <td>2023-05-07 05:37:12</td>\n",
       "      <td>2023-05-07 05:37:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1277</td>\n",
       "      <td>2324</td>\n",
       "      <td>893</td>\n",
       "      <td>2023-05-08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26377.48</td>\n",
       "      <td>0</td>\n",
       "      <td>Current</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Current</td>\n",
       "      <td>2023-05-08 05:37:12</td>\n",
       "      <td>2023-05-08 05:37:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1277</td>\n",
       "      <td>2324</td>\n",
       "      <td>893</td>\n",
       "      <td>2023-05-09</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>26359.27</td>\n",
       "      <td>0</td>\n",
       "      <td>Current</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Current</td>\n",
       "      <td>2023-05-09 05:37:12</td>\n",
       "      <td>2023-05-09 05:37:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1277</td>\n",
       "      <td>2324</td>\n",
       "      <td>893</td>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26341.07</td>\n",
       "      <td>0</td>\n",
       "      <td>Current</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Current</td>\n",
       "      <td>2023-05-10 05:37:12</td>\n",
       "      <td>2023-05-10 05:37:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1277</td>\n",
       "      <td>2324</td>\n",
       "      <td>893</td>\n",
       "      <td>2023-05-11</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>26322.86</td>\n",
       "      <td>0</td>\n",
       "      <td>Current</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Current</td>\n",
       "      <td>2023-05-11 05:37:12</td>\n",
       "      <td>2023-05-11 05:37:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480296</th>\n",
       "      <td>480297</td>\n",
       "      <td>1666</td>\n",
       "      <td>3017</td>\n",
       "      <td>1206</td>\n",
       "      <td>2025-05-23</td>\n",
       "      <td>527</td>\n",
       "      <td>17</td>\n",
       "      <td>19477.40</td>\n",
       "      <td>0</td>\n",
       "      <td>Current</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Current</td>\n",
       "      <td>2025-05-23 05:37:12</td>\n",
       "      <td>2025-05-23 05:37:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480297</th>\n",
       "      <td>480298</td>\n",
       "      <td>1667</td>\n",
       "      <td>3018</td>\n",
       "      <td>595</td>\n",
       "      <td>2025-05-23</td>\n",
       "      <td>392</td>\n",
       "      <td>13</td>\n",
       "      <td>31716.93</td>\n",
       "      <td>0</td>\n",
       "      <td>Current</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Current</td>\n",
       "      <td>2025-05-23 05:37:12</td>\n",
       "      <td>2025-05-23 05:37:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480298</th>\n",
       "      <td>480299</td>\n",
       "      <td>1670</td>\n",
       "      <td>3022</td>\n",
       "      <td>530</td>\n",
       "      <td>2025-05-23</td>\n",
       "      <td>279</td>\n",
       "      <td>9</td>\n",
       "      <td>17835.63</td>\n",
       "      <td>0</td>\n",
       "      <td>Current</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Current</td>\n",
       "      <td>2025-05-23 05:37:12</td>\n",
       "      <td>2025-05-23 05:37:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480299</th>\n",
       "      <td>480300</td>\n",
       "      <td>1674</td>\n",
       "      <td>3028</td>\n",
       "      <td>295</td>\n",
       "      <td>2025-05-23</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>33900.16</td>\n",
       "      <td>0</td>\n",
       "      <td>Current</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Pending</td>\n",
       "      <td>2025-05-23 05:37:12</td>\n",
       "      <td>2025-05-23 05:37:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480300</th>\n",
       "      <td>480301</td>\n",
       "      <td>1675</td>\n",
       "      <td>3030</td>\n",
       "      <td>1156</td>\n",
       "      <td>2025-05-23</td>\n",
       "      <td>468</td>\n",
       "      <td>15</td>\n",
       "      <td>14344.35</td>\n",
       "      <td>0</td>\n",
       "      <td>Current</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Current</td>\n",
       "      <td>2025-05-23 05:37:12</td>\n",
       "      <td>2025-05-23 05:37:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480301 rows × 15 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7403e8ce10371c9a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
